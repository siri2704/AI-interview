i think we're live we are live i see you live in the upper left hand corner which means usually you're live right yes hi great to see alex uh rick jeremy uh hi everybody greetings to everybody tuning in from around the world across many different time zones my name is venkat venkata ramani i'm the ceo and co-founder of rockset super excited to have to be talking to some amazingly smart humans here uh who really really understand the current state of the art for nosql databases there's so much advancement in these in this part of the stack in the nosql stack in the last few years i'm hoping to learn a thing or two from our experts some of whom really wrote the book on how to scale nosql systems uh and so i've been building databases all my life from oracle uh you know from grad school even to oracle to facebook and now at rockset and so this is going to be fun and without further ado let me introduce the guests so we have alex debris alex is the author of the dynamodb book a comprehensive guide to data modeling with dynamodb and the external reference recommended internally within aws to its own developers easy aws data hero and speaks regularly at conferences such as aws reinvent and aws summit alex helps many teams with dynamodb from designing or reviewing data models and migrating uh you know and migrations and other professional training to level up developer teams alex actually just finished a workshop with us at aws summit new york so it's a pleasure to have him uh welcome alex absolutely thanks for having me then cat uh next we have rick houlihan rick who leads the developer relations team uh for strategic accounts at mongodb uh before [ __ ] rick was at aws also for seven years uh where he led the architecture and design effort for migrating thousands of relational workloads from relational systems to nosql systems and built the center of excellence uh the team responsible for defining the best practices and design patterns used by thousands of amazons internal service teams and aws customers we're lucky to have him here welcome rick thank you very much i'm glad to be here and la and jeremy daley is also here uh jeremy is the gm of serverless cloud at serverless and aws serverless hero and he's also an adobe serverless hero he began building cloud-based applications with aws in 2009 after discovering lambdas he fell in love with it became a passionate advocate of functions as a service and managed services and now writes extensively about serverless on his blog jeremydaily.com which he publishes occasionally but also has a weekly newsletter that is a lot you know super active uh very very fun stuff uh called off by one what a great name and hosts the serverless uh hosts the serverless chats uh podcast too welcome jeremy it's a pleasure to have you here thank you for having me it's great to be here with this amazing group of people yes let's dig in um this today the the topic of the conversation you know is titled sql versus nosql in the modern data stack so let's let's round it up i think um there's so much talk about and hype around modern data stack is this and like you know the best thing since sliced bread but nobody really talks about no sequel in that in that vein there's almost as implicit uh kind of assumption around sql and analytics there so let's let's kind of dig in just to start with i want to really kind of catch up on the nosql kind of ecosystem tech right there's so much development that has happened um you know dynamo uh you know exposes particle sql there's a sequel like apis that are coming uh all across the board um and you know cloud spanner did something [ __ ] down sql uh at their at the reason uh you know uh summit so would love to kind of get uh you know people's take on uh what what do these systems mean like uh in a two-part question first is what does nosql even mean if these systems all have sql api number one and number two number two is what do these sql apis actually do right what is you know are they are they a replacement to the primary api is that for ad hoc analytics on the side what what is the actual use case for those apis and i'll start with rick because [ __ ] is hot of the press on the friends with our brand new sql read api absolutely yeah so you know honestly for me it's all about you know i know sql is technology sector is really about an rdbms replacement right and it's not i wouldn't say it's a sql replacement it's about an rdbms replacement right because you know if you think back and i talked about this in my session a lot what really made the relational database work for the last 40 or 50 years was moore's law right and the ability of the of the processing system to compensate for the time complexity of relational joins at scale and in 2014 2015 just that broke and and it's never been more clear than when you look at the top 500 super computing clusters right they can't even keep up with moore's law over the last eight years that's almost a decade right they've been basically rarely hitting the line and they invest in everything so all this does is it means that if you're running systems at high velocity running tight high time complexity queries then you're spending more money than systems that don't require it and no sql is about tuning the data model for the access pattern removing the joins replacing those joints with indexes across you know items on a table that are share partitions or documents in a collection that share indexes because those index lookups are low time complexity and those are going to satisfy your high velocity patterns right and that's what's going to do it cheaper so it's all about saving money right and then the cfo writes a smaller check he's happy and that's what we do with so when you say where does nosql fit in the modern data stack it fits in every single workload where i have high velocity well understood access patterns now the rest of it about the you know you talk about the need for operational analytics ad hoc queries absolutely that's where these read apis come in right so yeah you know sql is not really the enemy here sql is the language of data that people have learned over the decades and we want to be able to you know expand on that and support that but those high velocity patterns we need to be able to model the data differently so that they can you know run today now that moore's law is no longer working right we need to be able to sequel right sql does have a play in even no sql systems that's awesome alex what about what about where is dynamo what is what is this particle you know particle uh or ql uh that has been announced uh what you know is there anything else happening uh on the other nosql ecosystem that has caught your interest around very advanced apis way beyond you know the the key value kind of apis that all of these were you know started you know years ago yeah for sure so i mean dynamo i think has a pretty simple straightforward api you know it's got the key value if you want to operate on individual items then it's got the query which allows you to operate you know on a range of sort of sorted items within an individual partition i think that's actually like pretty straightforward and if you take the time to learn that stuff it it works really well and if you learn that stuff then you understand a lot about modeling so i i definitely recommend to people hey don't jump into particle right away if you're sort of feeling out nosql for the first time and you want to have that familiar interface because you know the interface may be familiar but the implementation is so different that you're probably going to you know end up in a sub-optimal situation so i always say you know there are like five apis you need to learn with dynamo and they're really pretty straightforward there's not a lot of complexity there it's really just around understanding those those fundamentals so i would say you know look at that stuff first don't just reach for something that feels syntactically similar uh because i think you'll sort of shoot yourself on the phone with that that's awesome so jeremy has actually had a lot of experience on the other side scaling you know really really large complex uh you know sql and relational systems so uh i think you know you know it is one way one thing to you know find it very hard to shard your mysql and postgres and scale it i think there's only one thing that is much harder than that which is killing your nose ecosystem uh at least that's what i think uh uh you know uh because there's so much more things to think about that is poorly understood and and about you know which is why people have to read books all of you all of you right yeah i like that you qualify that with what's so much more that needs to be understood that needs to be understood because it's very poorly understood it's all possible it's much harder so jeremy what is what is your take on uh you know scaling nosql systems uh versus sql systems and and and where is the state of the art there well i think first of all to go back to the idea of the interface i think whether you use a particle interface or a sql interface or you use a standard dynamodb api none of that matters unless you get your data model right right so if you're not so you can write good queries bad queries with any interface but if you don't understand the complexity of how the data is stored and partitioned and and denormalized behind the scenes and what other indexes you've created as rick said to optimize those access patterns it doesn't matter what you use to query it right it's just syntactic sugar on top of a complex uh data model so i think the the things that i learned from scaling my sql clusters um is is the idea of doing the sharding and essentially what we're doing is building a router table that use some algorithm to figure out which shard something was on which then routed you to a particular partition and then denormalized data so that we could access it from that partition without having to hop around a bunch of different places exactly what dynamodb does out of the box for you automatically um so like it's just it's now you get other benefits right from using sql and having the or from using rdbms because then you have that analytical the ability to do those analytics queries um but certainly that is that almost depending on what your use case is it's like a secondary pattern so um i i do think that again knowing what you're trying to do with your data and choosing the right system to power that is is is the first choice that you have to make and understanding where it makes sense to denormalize understanding that data model and so forth so i think from a scaling perspective you know nosql scales way better than mysql does assuming that you've built your data model correctly um and that and that's the biggest thing i think that uh that people have to understand that's awesome i would just emphasize that point it's important to understand that right it's about the data model and every database can be used badly right they can reuse the relational database extremely badly i've seen it over and over again i'm sure jeremy's now alex supposedly i'm sure you've seen it venkat right is you don't put the data mod together right you don't index the right attributes you don't write the right queries man this thing can be really really ugly and i've had you know that experience as well so that's a big part of any database as a big part of nosql right yeah that means i would just i think yeah just as yeah but i think sequel gives you a lot more rope to hang yourself there there's i agree yeah and so many tuning parameters it's like you can really specialize it if you're if you're a deep expert but i think like i always say the learning curve for dynamo is like hey you have to learn some stuff up front that's new and you know it's not exactly like an excel table or something like that that you have before but you can really get up to speed on learning like a good amount of dynamo pretty quickly whereas like to get that same level of knowledge in sql you really have to be a dba basically so so what you're saying is uh no sql systems with the sql api have you covered enough rope enough stick you know if anything no no no joke i'm joking no i think i think they are amazing no sql systems are are so developer friendly so easy to get started no they're amazing i mean i you know any any modern application you know is is starting there i think that's there's a reason for it right so so there's one thing that i don't want to emphasize i think that is uh the less talked about story everybody talks about data model like like us you know we say hey get your data model right 100 correct but i think there is a reason why you know there is a lot more flexibility that you can achieve with the data models that are possible in the nosql systems and sql systems right sql systems are a lot more rigid and in and i think it comes from the type system so that is my hot take which is it's the it's all in the type system you know it's not in the you know once the type system is flexible because the nosql systems are dynamically typed right and sql based typical rdbms systems are statically typed right it's like going from a c plus plus java programmer suddenly writing python or javascript and suddenly they can go very fast and there's a lot more flexibility and it's not just the programming language syntax it's the type system right it's it's way easier to to keep uh you know iterating so and it's almost like it's but it's it's a little bit more i agree with you to a certain extent it's the fact that you have to in in a relational database you store those types in homogeneous containers that are indexed independently of each other and the fundamental purpose of the relational database is to join those indexes right that's what it does and if i put if you take a nosql database any nosql database essentially you put all the items all those typed items into one table and you cut across a common index on on shared attributes on all those documents and and you have reduced all the time complexity of the index join to an index lookup right so everything is oh login oh login you sprinkle that with a little bit of denormalization you toss in things like aggregation the framework on top of that and you get a really really powerful system right now dynamo gives you some of this but they don't give you the whole picture right you can't get things like built-in aggregation queries to get there you have to do a lot of dancing with the data and tying things together and this is where when you say what does nosql where is it fit again in the modern stack the nosql databases are evolving to you become built with the purpose i like to say instead of you know purpose-built right the ones that actually are taking all that functionality developers are asking for right we need more than a database we don't want you know we need online archive we need sql apis for downstream consumers right we need you know search indexing that's real not just you know uh you know things that we play with with tags and things right and and mongodb built the platform to do that right that's that's what we've done we've we've gone out there and listened to that developer and we said we built this integrated solution at aws i was there for many years and you know the solution there was hey we developers need this let's build the purpose-built you know the thing that we'll stitch together right so trust me trust me rick trust me rick uh we here at rockstead we know a thing or two about how important search index is absolutely i know you do i know you're just gonna say we gotta talk about dynamo and rockstar we know we know about you are the other half you are the other half right honestly that's for those dynamic consumers that need that kind of functionality i say go there because it's more tightly coupled it's more it's more of a it's a more rich developer experience right one thing we love this community uh here at rockstead so like um you know the nosql community so yeah but it's not about rockstar let's bring it back so no sql systems um use cases right like i think you know the you know back in you know early days of facebook and whatnot you know the the real kind of meme or or the high level messaging around nosql was it's so developer friendly and and it's the advent of web applications which were you know taking off and um it was really you know you know built for a purpose at that back in the day i mean everybody says okay well why are nosql systems relevant and suddenly why did that happen in the 2000s well because web apps were very important and they were everybody was building a web app and it was so much more developer friendly now but the use cases now nosql systems have gotten so advanced the kind of solutions that people are building for you know from iot from other data applications real-time apps and what have you there's so many different things that are happening on nosql ecosystem now and so i'll start with jeremy like what are the what are the kind of verticals and what are the kind of application stacks that are being built on nosql now that we wouldn't have even imagined let's say in the early 2000s or whenever the you know the nosql system was born yeah i mean there's a ton of different use cases i mean iot is one of the things now where we produce so much data uh per second in the world that uh it gets kind of hard to kind of hard to store it but i mean i think it it depends on what um you know again i don't want to keep bringing this always back to the data model but one of the things that that i've seen with with using something like nosql specifically like a dynamodb is that if you're using it to capture like telemetry data or something where you're getting all this stuff from i o you know iot whatever like it it you just use a lot of data and and that data might never be looked up again right like you almost almost want to have to do something more that you want to aggregate it whether it's in a time window or something like that it becomes more useful than just storing a record that you then have to scan and do something with later which is why i think databases like time stream and other what's the other one there that that does that sort of time time database scale uh yeah what was that time scale time sk is a time scale time screen there's a couple of them out there now but there's some very interesting databases that are that are specifically designed around this idea of capturing data that is time time stream data like and being able to then run those aggregations and and make more sense of it and i think that that's another thing we have to think about where it's like nosql is a really great solution for storing data and doing quick lookups and having that you know that zero log in sort of uh the ability to to query it but if you don't have if you don't know what that partition is right then you're sort of really wasting a lot of um a lot of capability of of what or a lot of benefits of of that fast lookup because you're never going to look it up by that particular thing there so i think that's a mistake that a lot of people make is to look at something like nosql as being a way to just dump data into it and then they can scan it later wherever it just doesn't have that capabilities and maybe [ __ ] is doing more you know that they that they uh you know they can do better stuff with it now but for the most part if you're dumping data into a partition that partition should be known somehow is how i see the use case as being so if you don't know that partition and there's not a way to look it up even if it's like a you know based off of a ip address or something that you don't necessarily know but there's some way that it ties back to that that direct lookup um then i don't think i don't think nosql is the right way to do it so if you are using you know nosql to collect telemetry data from iot you're probably using it wrong um you know depending on what your use case is but that you know that would be my that would might be i actually i disagree with that i i mean some of the largest time series use cases in the world run on dynamo dvi architected them right i built them they run very well and they run very well with streams lambda aggregations to do exactly what you're talking about and time stream does you know i'd say to a certain extent some cases better in some cases more performance and cheaper it does when you look at the pricing time stream has a pricing advantage over dynamo and you know for time series use cases mongodb has time series collections as well i mean that's the it's cluster compression on the indexes it's you know doing taking care of those things that you need to do to do it efficiently really is what it comes down to and no sql databases can do that relational databases can do that right i mean it's all it's as you know it's about the data model right how are you going to build the data model to be able to support the workload and there's you know features and functionality in the database that make one may be more efficient than the other and that's then that is you know what i think all the nosql databases are evolving into graph lookup right is becoming embedded in in nosql databases you're seeing these features and functions now start to coalesce into the apis of the various providers and this is again one of the areas where i think we should have made a better i should have done a better job when i was on dynamodb team i wish we had i mean of integrating some of that feature function right yeah what another i'd like to jump and again i always love it when rick houlihan disagrees with me but um uh you know and again i'm not saying that it's not it doesn't support it because i think it does i'm just wondering if this is a conversa i mean i guess the conversation i'm going towards is is there more purpose purposeful built or purpose-built databases is there is there is there advantage to purpose built versus built with a purpose platforms right i mean atlas provides a platform that does those things and then we again we've integrated that feature function when you talk about the need for it that's the stack right where does the you know how much of this functionality belongs in the database and how much of it belongs as as things that need to be stitched together i guess that's how you approach it right i mean from a from a provider you know mongodb as a platform provider looked at it and said hey you know lucine powers elasticsearch lucine power solar lucine powers the most powerful you know search scaled out search engines of the world great let's make it a first class citizen in the api you know it's there right on the head node in an atlas cluster and local host replication and all those problems that i used to talk to honestly you know when i was at aws the big problem that the amazon service teams had with elasticsearch was the synchronization one of the reasons why i talked to customers about using rockset because it was a seamless a much more seamless integration right when they then stitch it together yourself experience right the customers had to do those things right yeah i think i think the if you think about the use cases i mean iot even i feel like um iot is just like even you know the problem that was there like five ten years ago right like i wanna even bring it more current like what about what about ai applications what about what about models right like what you know which how do you store them like let's say i have a bunch of vectors from you know coming out of my models and how do you do you know nearest repeating distance of all the vectors and how do i index them how do i store them so like um where is this going is does nosql have you know basically my question is really what is the is the nature of applications changing and is the nosql uh databases are they ready for it right like web apps even even iot i mean that was just an example i'm you know yes i think it's hard as jeremy is saying it's not easy but yes it can be done uh there's no there's no question about that you know you if you if you work with experts in and you know do your homework you can but you know maybe you also need a couple of phds in it like people in the panel have but let's it can be done there's no question but but i still think i still think if you're talking iot and telemetry it still feels like early 2010s this is 2022 right yeah the nature of our application starts changing again how ready is the nosql systems for that right i i'm interested in what you just said there that's a a really valid line of questioning to explore so when you say it's and i totally agree with that it's 2010 2015 right this is the iot problem what's the problem with so what is the problem that you're seeing today i i see the problem today is platform convergence right this is developers don't want a disjoining experience they want a unified tightly coupled experience they don't want to have to think about you know doing data sync between you know the nosql database and when you say is it ready this is exactly the reason why i'm honestly why i'm not in on the dynamo team anymore i don't believe it is ready for that next generation of solutions where you know developers want that tightly coupled experience they don't want who wants to build all that stuff yourself but developers aren't doing operational analytics uh it's my it's my sales operations person it's my marketing operations you know it's people here and that's where the sql read apis are coming in right because that's the that's the ability of them to be able to run those ad hoc analytics on data because i don't really care about the efficiency of an ad hoc analytics query i don't care that it comes back sub one millisecond you know as if the person who's making that query is not running a thousand times a second you know what i mean these are dozens of requests a day that we're handling right so those are the corner case requests that honestly as long as i have a way so i have a way to do that then that's great what i really need to optimize are those things that are running thousands of times per second right prime day front office you know shopping cart service right i got oh i got all kinds of stories about that right the gold box to service on on the front page but wait what what are the five deals that are hot right now know these are the types of things that matter right other other than that operational analytics and all that that's great but you know what i can run operationally i list queries one time every 10 seconds and i'm going to always have a report that's never going to be more than 10 seconds still if i just if i cache the output and throw and i did this with dynamodb right you had running aggregations running all the time that you would you know it's better with [ __ ] where i can calculate it in real time and i don't have to worry about container failures and lambda you know duplications and double executions and all that are you rick are you saying real time is better thank you i'm saying i i i totally agree with you you're giving me all the thoughts i'm giving you the ammunition this is the good stuff right because i agree with you this was the you know those land executions those are tough because they're guaranteed at least once right so streaming aggregations through lambda are not as reliable as maybe they need to be for some of those you know for some certain use cases others don't matter downloads i agree i agree real time is better than batch trust me i am yeah i know you know i'm betting the farm on it but alex like what other what other what was the nature of application changing you you see a you you know you see you work with like you know leading edge companies trying to scale you know dynamo and other systems like what what kind of new like application categories are you seeing from from your yeah you know i don't think of verticals that that much really like i think dynamo and which is mostly what i work with is flexible enough to handle almost everything especially if you can flatten it into you know 2d or something like that so you can do geospatial lookups you can do all sorts of things with dynamo so i don't think it's that much i just think what i've seen over the last five-ish years is just like more people understanding and considering no sequel i think there are a couple big things with that number one is just like how well dynamo in particular like worked with serverless applications right like you saw aws land to come up it didn't work well with relational databases and like before that dynamo was like sort of reserved for these high scale applications like rick is just going around inside amazon helping all these teams learn all this stuff and not all those were big right some of those were small or like you know you're going to external customers that have really high request rates and things like that and there's all this knowledge that's like in this tight circle but it's not getting out and then you see like this service community being like hey i want to learn how dynamo works you have rick doing his reinvent talks and like sharing all that stuff and now it's like now there's a community building around that stuff around that and i think that's helping the adoption more plus you're just seeing better managed services like you know mongo's mongodb serverless and more integrated platform and all sorts of things where like i think you're seeing people you know the more average developer the regular developer the regular web application able to and and wanting to take advantage of this as compared to right so long tail is growing for nosql right i think what we're seeing is a shift in the developers mindset now the skills are starting to become the early majority is arriving and people understand more how to use this technology right a lot of that is alex's work for the dynamodb community jeremy's work the things the stuff that i did right it's what it really raised the profile of that whole and i agree the serverless aspects of dynamodb are unmatched in the world today the elastic scalability the you know the things there are things that that it can do that you know everyone else looks at with envy right there's other things that it falls short of and this is the you know it's a question of as a developer what what's what's going to be you know the best developer experience for you the you know i focus on the long tail i work with strategic accounts you know 90 of the revenue for any database company comes from 10 percent of the customers that's who i work with right but but i like i agree with alex what i've seen with that that long tail developer experience is just broadening out and we're starting to see more of it uh and and why again it's because the the efficiency of the of the solution is better from a developer experience perspective and the cost efficiency is better it just drives a lot of dimensions that developers you know make it makes it easy i'll give you uh yeah i totally agree i think uh you know people people don't often think of this as a business decision but at the end of the day it really is because um it goes back to what jeremy said that was very important which is you know these really special purpose databases for like a particular graph database or a time series database they do have a role in play and i would say the the rule of thumb is always this which is uh what is what are you uh spending more on are you spending more on your infrastructure machines software hardware or on your people right and so when you're small it's always people and so people make people think it's a developer decision it's actually a business decision that save money on you know developers can be more effective more efficient they can you know they can be more productive you know what it actually makes sense it's actually cheaper to use no sql systems for the business but once the scale crosses a threshold even if it takes four people to work full time to optimize that particular build out because by going from a generic solution to some special purpose thing you're going to save enough resources save enough hardware because you're already spending way more right tens of millions of dollars in hardware every year you know what at that point there is a there is a room for uh special purpose system so so people don't think of it as a business decision but if you really look at it as a economist you know what is the what is the price of building this app and you you know include everything yeah yeah and you then it will all make sense yeah totally and i agree with everything you're saying the thing except where you say there's a place for special purpose systems because i do believe that that's functionality should be embedded in the platform this is what we're hearing from the developers they want this function great let's give it to them and and what does it take for cloud you know to get that functionality that really to drive efficiency it takes things like time series collections okay i can implement that inside of one platform or i could create another platform that does that specifically right i think people will get started there i think uh you know my my you know if my uh take is right i'll tell you developers would want you know you're hearing from developers wanting this i absolutely agree with you and then the cfos would be pinging those uh vp engineers and saying get off of this thing you're you're misusing this you know what are you doing right let's go you so they won't hear you see if they won't call you they'll call their you know that's returning teams and so that's what will happen and so this goes back to jeremy the people that will be moving off of that would be basically people that are clearly not the not the developers talking to uh but no i think they they both have a role i think the the real the real another thing that you're all basically saying is that that threshold point is constantly going higher and higher right this is another thing you're saying there's always a threshold point but things are getting so advanced and and so much better that uh the scale at which these things matter is only in you know going higher and you know it used to be you know when you're dating the big data problem is becoming the biggest becoming everybody's problem i i said this five years ago exactly and more and more and more right we are not talking about terabytes anymore we're talking about petabytes we're talking about i had i've had the first conversation with the customer before i left dynamodb it was about a a zettabyte table right they were talking and it's like and there's 100 petabyte tables in the dynamodb ecosystem right these are these are massive workloads and again everybody needs to think about scale and this is why it's most important we've all talked about this the data model is everything uh understanding the access patterns and and tuning for those high velocity patterns is really no different it's really noticeable it's also the relationship so so let's let's talk about this now uh let's talk about this can we jump into this into into the pricing and the yeah the developer experience and cost right so let's go let's go there so let's go with that yes the database i was trying to think about by the way was influx db which is a type of series database that that is pretty good it gets a little expensive whatever but so this is my point about um using purposeful built databases is there are you i find i think like dynamodb is like this utility platform which is great you could build all kinds of stuff but if i want to do what rick said and i want to create aggregations and running aggregations you already mentioned that even though it's guaranteed once it might not be 100 accurate because there are going to be things that don't always do that but i've got a bill i got to enable dynamodb streams i got to set up lambda functions i've got to have all of those things set up so that i can write back to the table and do the aggregations and then maybe use those the rolling time windows whatever you're talking about people like that is an investment in terms of setting those things up and if i've got a massive amount of investment to do that whereas if i just plug in influx it just works for me right out of the box save a bunch of money and maybe if the platform had decided to implement time stream features inside of dynavo we wouldn't have to worry about a purpose-built solution this is my whole point right but this is what but my point goes to the thing is that it doesn't do that right like you have to build that stuff out that is all bespoke it's stuff you have to do after the fact and you've got companies like rockset and some of these other ones that are great because they'll take that data they'll do it for you you could also take your data and stream it into kinesis data firehose and dump it into c s3 and then query it with a theme like there's a million different ways you could do it but i think it's very very i mean as a developer myself i wish i just had a solution where it's like i can just write data i don't want to write that code i don't want to say i don't want to exactly yeah i don't want all this stuff i want to hit a button and have it happen i totally agree with you right i fought for these features for years instead we got timestream we got documentdb we got you know eventbridge which is cool i i agree but you know we saw all the expansions on you know everything that was like okay stitch it together stitch rick loves aws so much he hates it actually that's the hard part about all this is i actually love it i love it so much it's just the amount of cognitive load that goes into building these things out and then continuing to manage them it's just a better solution is where it needs to be and so um anyways but with the price thing like one thing i just want to point out um in terms of cost as well is you pick a solution like a dynamodb you use on demand initially especially with development tables and things like that and then you get to a point where you're now provisioning and let's say you're provisioning 3000 rc user whatever you're doing right i mean you're that is going to get very very expensive and it's going to get more expensive as it goes and it's linear growth so i love what [ __ ] did recently with their atlas serverless where they said you get to a certain number of read requests per minute or whatever it is and then it drops to 50 of the price and then you get to some other thing it drops to 90 of the price and it's actually real relatively low numbers like if you're spending more than 30 dollars a day on read queries with mongodb you automatically get that benefit we don't get all of that with with some of these other things so i i think that's an interesting thing to think about not just with with databases and nosql and so forth but just the way that we scale and price how any type of these linear on-demand growth type things work is the cloud provider should be able to start figuring out where they can pre-provision for a customer regardless of how they build their data um and then essentially you know the whole own the own the base rent the spike type thing um i think that's that's certainly something we we've got to think about because i think that the scale here is great it scales no problem but you start spending a lot of money to do things that you could be done more efficiently and i think that in some cases maybe providers are taking advantage of people yeah yeah but i also expect that dynavo honestly they will unify that pricing model we're going to see something similar to tiered scaled pricing for on demand but even even the tiered scale pricing with mongodb though at some point it's going to be cheaper to run the cluster right it's going to be cheaper to run the atlas cluster serverless has a premium as an overhead price dynamo has it too right if you all those things you talked about at some point i'm provisioning 3 000 constant rcus or whatnot i'm going to go talk to you about reserve capacity and all this and getting discounts on that as soon as you do that all of a sudden it's kind of like a fixed infrastructure line right now and you can't adjust it if once you buy that reserve capacity contract is like three years at x you fill it right so again it's just there's a cost to serverless there's a cost to elastic at some point in the database and i've always thought this at some point in the database there's a baseline capacity that has to be provisioned and you know what you want to be able to do is turn that ratchet up and down when you need it right and and that's what atlas clusters gives you right the ability to kind of schedule those scaling events and say size up size down you can do that with dynamo but you're always paying the overhead of serverless always right as you adjust that that dial it's never you're always and and there's no secret to this i mean the service team tells you there's a reason we can give you instant capacity right because we're overcharging you for the capacity you're using right so at some point that's great for like i said that long tail the wide tail and this is why it's the dynamo community is growing phenomenally because it's so easy to get going and you know what honestly if you architect your nosql workloads well it's not painful to move it either to any other platform right if you follow the guidance that alex and i and jeremy have all espoused for dynamodb and you did that well moving to mongodb is going to be like a snap of the fingers right especially because dynamo scales you can have terabytes of data out there and just turn up the fire hose and get all that data out really fast if you need to right that's great so let's talk about these uh that you know they read the book they they watched all of your videos and they did all of this and now they have a 100 terabyte a petabyte single table dynamodb you know this thing that has you know that follows everything that that you all say and then now now a business team comes around developers are so happy because they can do anything they want and a business team comes around and say what do how do i do anything here right like i want to understand what are we selling why i want to understand you know what is not selling what is working what is not working and all of that information is locked up in this petabyte single table no sql system what do what do i do how you know where do i start like i like so i would start with you first with me yeah i'd say you know you really have to figure out a little bit about your needs on it like hey do you have batch-like needs are you fine with batching do you have more real-time needs do you have highly mutable data is it more immutable that you can just sort of stream out and figure out different things you know i tried to give you a pitch for rockstead earlier when jeremy's going on about all this configuration and roll-ups no but like i just want to tell people like you can do some of that stuff like pretty quick button you can do aggregation roll-ups all that stuff configured in in rockstar so check that out so but like you know again check out is your data immutable uh do you need real time um different sizes things like that hey but you only need go ahead sorry no my question is really uh how do i even get this system into a sql based system like just just like and i would say like just let's not talk about rockstar for a second like you know let's say i'm i'm i'm on-prem let's just say the cloud is not an option right like i have a cluster of let's say mongodb and i have like this giant you know collection and it's deeply nested data that is like you know a million different field paths in there it's dynamically typed and so all the different attributes are all like you know you can't really you know know even what fields are in there wild card indexes don't work i can't replicate this and now my business team wants to know let's say i'm a a massive multiplayer online game and i have my own data center where i have these clusters and every little digital you know you know you know uh artifact that i'm selling you know selling is tracked there and i and there is like a million of them and i want to i want to figure out what is selling you know you know oh something changed in my in the app and we rolled out and suddenly we're not making as much revenue i want to know which digital goods used to sell a lot and now doesn't sell anymore and all of this information is locked up in like this petabyte uh nosql so what do i do how do i how do i get anything how do i get any answers for for the from for the business i mean i would say if you if you have an on-prem fi mongodb cluster and you wanna do analytics on it that's like my nightmare i would i i would not say that i would be really happy to have to talk to that customer yeah no i would ask i would just ask how did you get a petabyte of data and nobody was asking you to analyze it before or i've been i've been in pain now the pain is just much much larger right like it's not that because again this goes back to when when early days of a gaming company and whatnot you're really trying to get go for growth and and the most expensive resource you have is your team and you speed of iteration is important so how do you get to a parabolic data you suddenly have a viral application that you turn around six months later every kid in the in the world is playing yeah okay there you go that's how you get it because you know the the the adoption grows right but but this is really i think jeremy's point on how much there's a lot of poorly understood concepts here right you know even like you know things that are very um you know uh things that you take for granted that you say very subtly actually you say sequel is not the enemy which basically you're saying sql is the language uh in support data model it's about the type system and even all those subtle things are much much nuanced and phd level topics if you ask me and so you know what it always is database videos data modeling database technology in the relational world i hear developers all the time and i'm guilty of this myself i know how to use the relational database oh that query is optimized i wrote it okay i had director of engineer nearing look at me one day when i told him that when he was like he wanted to hire a 1500 an hour sql guru to come in and fix our stuff and i said i wrote that query it's optimized you looked at me said that's why i want the 1500 an hour and i gotta admit he was in there for a day cleaned it up and the servers were humming right and literally you can you can double the infrastructure you need to support a workload by not indexing a table in a relational database i mean it can be tremendous impact right and i've seen this happen i saw i saw an index get dropped on a uh we call a lookup table lookup table had like 20 items in it but the index got dropped so you know every single thing joined every query in the world on this system joined that stupid table right all of a sudden you know it was they deployed and it was like whoa roll back everything's on fire right the cpu is going through the roof the memory's crushed you know what are they doing you know joining a 50 line lookup table with no index right this is this is the kind of stuff that can happen i didn't do that that wasn't my fault i just saw that sure but you know somebody just deleted the wrong line in a ddl script right these are the things that happen and not only that but people just create bad bad data models right by default developers don't really know the ins and outs of data modeling even in the relational world right dbas do and you talk to any dba who's walked in after a developer and they'll tell you the horror stories that they've seen right that's the bottom line same thing with nosql what you described to me was like a distributed monolith right when you walk in you see 1340 sql tables are in a mainframe db2 instance and someone says i heard that mongodb is going to be able to replace my db2 and i say oh god you know let's talk about the two or three years of you know pain you're gonna have to go through to redefine your api boundaries and segment that data up so you can actually do this right you know this is the this is the path you have to take if somebody did that to their nosql database then they did the same thing that they did to the relational database and it's a big mess and it's just going to take potentially even years to clean that up right i mean that's that's what happens when you when you make messes that's why it's always good to understand the best by alex's book that's right strongly strongly endorse it uh jeremy you have any do we have any advice on with people that are going all in and and how does how should they think about analytics on those things i i think alex gave us a few things to think about on you know think about it mutated data do you want you know real time batch uh and rick is talking about you know some systems are offering sql api that's built in for some of these people what else um what else would you suggest things to think about and even he could probably talk about even in the serverless world right let's say people use people got that maybe not petabyte maybe terabyte maybe hundreds of gigs even but on the serverless data abstractions that that that exists right where it's so easy to get started well now suddenly my app has gone viral what do i do how do i how do i you know empower my business teams uh with with uh with what they are looking for right yeah well i mean again the the what i've always done is taken data from uh from dynamodb and attach it to a stream and then replicate that somewhere else one of the things one of the use cases i used to love um is basically reading off a stream and then writing that data into you know in batches into uh the aurora serverless because then you could basically query that data very easily and like rick said we're talking about 20 30 50 maybe a couple hundred queries a day as opposed to thousands of queries per second on the actual data that needed to get read back from the application standpoint so um that was one thing that i i've done quite a bit and then the other thing was is that again adopting a pattern where writing that into just s3 and using something like athena to query it um but that is uh it's a little bit harder to do that if you have data that is mutating and people are updating records and things like that you can't just write it to s3 and then and then query it that way that's where the the you know something like aurora serverless works out a little bit better in that case um but i think the other thing too is just thinking through co-location of data i think if we talk about the single table versus the you know multi-table debate um you know it was always oh one table per application and so forth i mean i look at an application i think of an application more as a microservice or some micro microservice right some something that is um you know a smaller piece of data and the data that then needs to be co-located within that so unless you're doing um you know i look at it saying unless you're doing joins on the data and i know you're not actually doing joins but unless you're pulling relational data back through a single table um that that's really where that single table goes like i would never mix time related time stream data with um you know with operational data and things like that in a single table configuration data operation data you can separate these things oftentimes i would recommend that especially with time series data don't don't muck with those time series tables just drop those things every day roll up the the summary broad data into summaries you know keep the summary data around maybe maybe store the summary data in with your configuration data because that might be interesting depending on the access patterns right correctly it's all about data that's accessed together should be stored together be in the same item or it should be in the same table or the same collection if it's not accessed together then who cares right the access patterns are totally independent how many tables up to you whatever your preference is oftentimes the data life cycle is easier to manage when different types of data are in different containers so it's one of the things people talk about you always want one table for everything no no i don't want one table for everything i want one table for everything that again when the high velocity patterns are accessing the data together then store it together that's the mantra it always is dynamo [ __ ] you know you name it they're they're all the same yeah nice awesome yeah that all makes sense um this is a super valuable um you know [ __ ] [ __ ] atlas and dynamo i mean aws are you know partners to heart we love them uh here at rockset um some of the patterns that jeremy was just talking about is literally what we also see so my my two senses um you know mutable data immutable data if you just want like in real time you know i want to have my cake and eat it too you start with no sql system scale there and if you want another takes on on that in real time you know literally it's plug and play and uh you know the the other unsung innovation that has happened in both uh and all nosql systems that we're not really celebrating enough is the change data capture systems oh right so so you know people used to write open source oplog tailors for [ __ ] not so long ago right and now the chain stream api is wonderful mango chain stream is brilliant um and dynamo streams is probably one of the best dynamo streams will give kinesis a run for its money it's that good right uh because if you don't really need even key value lookups you know what you could still write to dynamo and just get dynamo streams out of there and like you can be your poor man's kinesis it is that good so this is a unsung hero and that is exactly what rockset also leverages and so when rockset has all these built-in connectors we couldn't have built it without dynamo streams and and [ __ ] chainstream yeah but now yeah and now we have tapped into it now you make a change to dynamo or [ __ ] within one to two seconds you have a fully typed fully see you know indexed sql table on the other side and you have full feature sql on that data so you can have your cake and eat it or eat your cake and have it do whatever i said but um but i think i think that that is another very important innovation i think the advancements in the nosql systems are or beyond what you can do within it's also how easy is that ecosystem is to interoperate with the rest of your staff because no matter yeah because no matter how big it is it's still a piece to the puzzle right you you still have so many other problems that you want to use other systems for and how do you plug and play that whole ecosystem has gone like gotten so much better so so i think um you know you know that's a on that note i think we're you know we're time time's up so we're going to give everybody let's say 60 seconds for closing thoughts uh we'll start with rick rick any closing thoughts maybe loose rick yeah oh yeah sorry i you kind of broke up for me a little bit sorry uh yeah sorry we're closing comments yeah i know i always have closing comments right right yeah again it's all about no sql for me right the the the this place in the modern stack is in every app you know the moore's law is no longer balancing the equation for the relational database i don't think sql is dead i think sql is absolutely quite alive because like i said it's the language of data but i don't think sql is any longer is no html is no longer tied to the to rdbms right and the backing storage of the data is irrelevant now the shape of the data in the back end as long as i have that api in front of it then i have the ability to run those workloads right and then it comes down to velocity sensitivity latency you know and whatnot and that's that's really where where the the the relational database starts to excel but from my perspective you should always be looking at nosql that's fine and you guys know that that's what i've been for years [Laughter] awesome jeremy um yeah i mean i just say uh you know speaking of change data capture i mean uh the the work that i think uh it was quad shams who did most of the dynamodb um uh stream work and and i think was part of that team there like that is just an innovation that just i almost became like it's just now it's like table stakes for any type of database system um you know and that and and now if you think about the idea and the power of saying that the the most important piece of if you think about applications in in years you know years past it was capture someone someone's request and then process that request somehow and then then you know make that request permanent or save that data right you know persist that data whereas now you can very much just switch that paradigm to say make sure we capture the request and persist the data and then we have this whole you know uh this ability to run whatever we want on that data that was was there too so that post-processing capability yeah is just absolutely amazing and i think if people think about it a little bit differently where i'm not manipulating data and saving it into the database per se i mean i am doing that to maybe i'm shaping it the right way whatever but then after anything i want to do on it that guarantee of of being able to then see the data see the changes to the data and and so forth gives me just amazing capabilities so i think that's one of the things too where looking at sql data and things like that you're very much so trying to write to multiple tables to try to make sure that you're mapping all the things correctly or as opposed to just dumping a document somewhere that's structured the way you want it to and then having that capability post that to really do some amazing things on that data now you can do it with you know stored procedures and some other stuff like that on on on sql or rdbms as well but i think this this new modern way that we're looking at change data capture is uh is uh very very very amazing and a lot of things that you can do whether it's storing it in sql or again you know processing a million different things off of it is uh is just an amazing sort of evolution of where we've come awesome alex yeah for sure i mean you know we've said a few times that the data models are everything access patterns are everything i think one thing that i've appreciated about about learning nosql is like i really understand the fundamentals a lot more you know i worked with sql for a lot of years before nosql and i just i i didn't understand what's happening under the hood that query planner hides so much from so much yeah they're just like what's going on but like dynamo and nosql it's like hey you learned how partitions work and how they're doing that how that sort key is working you learn how global secondary index is working you learn sort of that stuff you get an understanding of that infrastructure you learn to see what's expensive what's not expensive how you can model that stuff you know like another pitch for rockstar like you guys have done a great job on this druva just had like a really good video on like the alt architecture and like what's happening and and what are the different trade-offs that that rock set mates and like you just gotta understand like all these data systems have trade-offs and if they hide them from you then you can't really take advantage of like what they're good at and avoid what they're bad at so like make sure you're understanding the infrastructure under the hood and using that correctly then awesome use the right tool for the job understand the tool you're using what trade-offs it has and when to use it uh brilliant i think this is great uh i had a a bunch of comments a lot of positive uh you know feedback most passionate discussion about databases i've ever heard so so awesome thank you for uh you know listeners uh yes we're all super passionate about it um i think i think there's something really pure about building a database and and working with uh working in this part of the stack because it unleashes so much creativity in the world right absolutely and one last thing denormalization is not a dirty word until you want to write something or update something maybe you know uh sql gives you enough rope to hang yourself no sql systems gives you enough sharp knives to cut yourself you know no but but but they're they're as as i like said they're all wonderful tools you know you can you can build amazing amazing systems that are massive scale uh you know with these systems you know work with experts do your homework pick the right tool for the job you know and uh best of luck you know go keep building keep building awesome apps that we all love to use every day and thank you everybody thanks for having us appreciate you having us conversation see y'all see y'all later yeah bye