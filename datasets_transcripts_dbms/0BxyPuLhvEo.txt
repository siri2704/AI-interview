okay so thank you Rohit for the introduction and we can start today's session okay so as Rohit already mentioned guys so this is the second session we have the remaining session coming the one which is highlighted is today's topic we are going to talk about context grounding and the vector databases the way we are going to structure today's I'll start the session i'll show something and then I'll hand it over to Manoj to give you more context around the same topic okay so with that let's get started okay context grounding right so we'll again not directly jump to the technical or to the presentation right we'll just start very simple right so for example you are attending this session or you are in a meeting and you have received a text message or a email which says it's ready that's it right you just have received a message uh on your mobile phone or uh in your team slack anywhere right and it just says it's ready now if you have ordered a pizza and maybe it came from an unknown number then you know that you have ordered a pizza if you are expecting a parcel then you may be parcel but without context what is ready so for example if you and me uh we both of us are working in a project and you received a message saying it's ready then I understand that yes it is a project you're talking about a dinner you're talking about pizza you're taking talking about a parcel but if you just receive any information without context you are not able to understand anything and that is why to understand anything we need uh context right let's take a different example whenever we talk about context the way it is said and the tone and the setting is also important for example I just say that you are unbelievable and I just said it to Manoj but when I told this I was smiling i was happy that means when I say to Manus that you are unbelievable at I means that I'm saying Manus that he might have cracked a good joke or he might have something which is very funny however at the same time if my tone was angry and I was upset that means that the same thing the input is same the context is different which means that the surrounding also has a impact which means that your tone setting also helps you to understand the context context like your facial expression where you are sitting did you just punch the other guy and say that you are unbelievable that means you are angry if you are smiling that means it was a happy thing right so that's why to understand any information we need to have the proper context other information the tone and the setting the same thing you would be able to notice in your day-to-day use cases or in your life such as when you work with maps and locations right so if I am with a friend right and I just say that take the left at the next light now you would not be able to make sense out of it if I just send this message directly to your mobile phone however if let's say you are in a new city you are driving a car i send you this message and I just say turn left at the next light now I do not know what is happening around you you are in a new city I am in a new city so this instruction become confusing and that's why it is important to give the context and as human beings whenever we talk to each other we use a lot of context which you might be using but you might have not realized that this is context grounding and that's where we are coming to this topic now right how does context help us as a human to understand this thing humans heavily rely on the context for example clarity in ambiguity this is a phrase which which means that for example bank could be a river bank or it could be a financial institution right it can be a river bank or it can be a financial institution if I say a sentence like this I saw a bank on my way to work now what do I mean do I mean a river bank or do I mean a financial institution but let's say if I'm talking to Rohit who is already working on a bank and our conversation is happening around banking financial institution money which means that we are talking about the financial institution but let's say the context of the conversation is more towards nature river valley then beats I am talking about the river bank right the second thing is understanding relationship right so for example you are sitting at a family dinner and someone says pass the salt right so there was 10 people sitting in a dining area and just say pass the salt now as a human you do not tell specific person pass the salt but the person who is nearest to the salt just take it and pass it back to you so which means that before you respond to anything it is able to understand the relationship and that's what as a human we do and then it also help us to make decision if someone just say to you let's go out right now let's go out now when you see listen this automatically you will see that what time it is what weather it is what is the location whether we are decide uh going for a walk for a dinner or a weekend trip so for example it's already let's say 900 p.m in the night and uh the weather is good we all are hungry and somebody says let's go out you automatically figure out that we are talking about a dinner right so that means that hum as a human we heavily rely on the context and now if I just tell context grounding in the technical terms you would understand why exactly context is important okay with all this background now let's see how LLMs when I say LLM it is large language models one of the fundamentals for building the agentic automation how LLMs use context so large language models like chat GPT are designed to process and generate humanlike text to effectively to do that they use context so imagine you are having a conversation at a friend now this time the friend is nothing but an LLM you automatically remember what you have been talking about so when I talk to let's say my friend Manoj I don't give him my complete background that hi I am your colleague I am also an MVP we both are doing a session and everything because it has all the background information about you and you directly start the conversation and and when you talk to a new person who is not known to you then you introduce yourself and you give the context you give background what is the conversation about right so that's the same way any LLM use the context to derive the final information out of it how does it do that technically in the background what happens it breaks the information into tokens so I have given it a sentence that I love apples what happens in the background any LLM is going to take that input break it into small small chunks which is known as tokens right so you could relate it to OpenAI tokens LLM tokens right when we uh go to CH chat GP and all consumption tokens so this is the tokens right so you give a sentence you give an input that LLM divide into different different tokens then every LLM has something which is called context window it has a memory right how much memory it can store and that part is called a context window so llm would have a context window that context window would have a memory whatever you pass as an input goes to that memory it will feed in and let's say if it is way too long then the most might token might be only considered right so you need to understand that LLM has something which is called context window you might have seen this when you keep chatting to any chatbot or any LLM or OpenAI something like that after some time it start giving hallucinations and it keeps you start giving vague responses right because the context window size is limited or it might be full different LLMs have a different context windows right now predicting the next word this is what LLM actually used so now based on the tokens which are available into the context window next time when you say that I love apple and banana but my favorite fruit is it is able to relate that it could be mango it could be grapes it is not going to give you something like I love apple and banana but my favorite fruit is a laptop right because that does not fit in the context so that's why when working with any LLM agentic AI context becomes important and let's try to see some of the examples conversation flow right so tell me about docs and then tell me about what is their diet so when you say tell me about dogs the next statement when you say tell me about their diet it is not going to give you the diet for the human person it is going to give you about the dogs only this is an example of context when you say it and all it is able to understand you can give input to LLMs like summarize the article and explain how it applies to the market the LLM understand the context and then explain to the marketing you can actually revisit the previous inputs also you can just say that write a poem about rain and now you say make it funny but when you say make it funny it already understand it already had a context about the poem right and then the LLM understand the input and provide you back the output okay so now with all this background I'll stop my the screen and I will just uh maybe I can just cancel this this is our input and I'll just share my screen again with autopilot right i'll take a pause guys if you understand the context grounding just maybe comment context grounding so I understand that we all are on the same page and then you just comment context grounding so I understand that yes great okay I can see some of the comments right now this is autopilot for everyone okay and this have uh new chat and everything right in case you don't have the setup we will share the links on how do you set up and all Manoj has shared in the previous session so you can refer that as well uh we have the recordings all of this material is available so this is uh the autopilot for everyone now let's see how does context context affect the things if I just go here and I write a prompt I'm just copy pasting it from the PP to save time right how do I reset my password now what happens here autopilot or any LLM in the background it understand the context and then it will try to give me some of the response and then it says that hello MKkesh I would be happy to reset the password go to the login page click on forgot password enter the email enter your password and so on and so forth right it has given me the response but this response is not good for me however if I would have given it a bit more context text which means that if I would have given it a bit more background something like this right a corporate user is unable to log to the AD active directory because of the forget and password provide a step-by-step uh guide on resetting using the SSPR portal ensuring the security compliance and the minimal downtime now the request is exactly the same but what is happening is I am giving it more context so that's why whenever we talk about agentic AI application agentic automation context become important now if you see this output make more sense because input was defined and I had given it a proper context as a developer we say that you can use autopilot to let's say code so I can just go here and I say new chat and let me just try to uh copy paste one prompt i'm just saying fix the code for me okay and I'll just paste a Python code okay so I am talking to an LLM and I'm just saying fix the code for me but I have not given the background what do I actually want to fix i have not given the context so yes the LLM has responded to me but it has responded in a generic way however if I would have given the same prompt something like this I am trying to calculate can you fix the code for me with a little more context where I'm saying that I want to include the 10% tax on this now what will happen with this context the LLM would be able to respond me much better and that is why whenever we talk about any agentic application when we build in the upcoming session context grounding becomes important so in simple terms context grounding simply means grounding the context of the LLM response so you get the response what you actually want right so this was a brief of about the context grounding and now the next thing is I want to quickly show a demo which all of us can relate to so we are having this sessions right now if I go today and I ask it a question maybe I'll just uh copy paste it again i'm using an LLM i just go here and I say what is the session three into the transition to the agentic automation webinar now this is connected to uh internet it has a lot of context a lot of information but what happens here it says that MKkesh I do not know where is this agentic series which is the session what you are trying to do it has no information about it and it says that I do not have the context or I do not have the information now what as a developer I can do here is with the UiPath products you can enable the context grounding right so what I have done is if I show you my screen quickly I have a PDF which is available which is nothing but the same uh event details which we have uh from the page right community page what I'm going to do is I'm going to teach the autopilot that this is the context so for that we'll just go back to our uh staging portal for me I'm using staging you might use the cloud the steps are exactly the same right so whichever tenant you are logged into so you just have to go to that tenant i'll go here i'll go to the admin right and in the admin this is the same place where you have enabled the autopilot for everyone you go to the AI trust layer and then here you see this guy which is now the context grounding right so now when I say context grounding I hope you guys have the background that what is context grounding right so I'll go to context grounding and in the context grounding I have these two folders which are coming from the orchestrator it is asking me which folder you want to create the context i want to create it in the autopilot folder and then it is asking me to add a new here so I go here add new and it is asking me to create a add new index but at the same time it is asking me to provide a storage bucket now I do not have an storage bucket so let's create that first why do I need a storage bucket storage bucket is a place where you can store the file so that autopilot or any other agent uh/ any other LLM can reference to so to access the storage bucket you simply have to go to the orchestrator okay so what I'm trying to do is I'll simply upload my session details to storage bucket link the storage bucket to autopilot we'll ask the same question and then hopefully it should be able to give me the details right so I have these two folders autopilot and this I'll go to autopilot in the storage bucket I don't have any information as of now absolutely blank I go here and I say create new storage bucket and I can just go here and I say session agenda and good practice provide a description right and then I just say add so This is now a bucket now into that bucket I'm going to upload the file you can have multiple files so for my use case I only have this PDF which is having the session details so I go here and I say open and I say upload we'll just wait for it to upload the file is uploaded successfully onto the storage bucket but still your autopilot for everyone does not understand which storage bucket and all to connect so for that we'll go back to the same place admin AI trust layer context grounding in this folder add new right you have to create an index so I would say that this is index for my sessions right and then I can just provide a description that what is this index all about good practice this okay and then what is this kind of you can always use the integration services connection we have put it in the storage bucket it's asking me which folder it's in the autopilot folder what is the storage bucket see session agenda and what kind of files this means that you can restrict the files but I'll just select to all and I say sync now now what happens now this context grounding is available for me into my admin section but still it is not hooked up to the autopilot so for that I just go to this tab here which says autopilot for everyone select the tenant and this is the same place where you would have installed autopilot if you expand that there you would see a section of context grounding you can expand it and then you just have to enable the index the index for me is autopilot index for the session and you have to define briefly that what is that index all about so I just say that this document is having the details about the agentic series on transitioning to this you can add more details providing more context and just say enable and that has added to the autopilot in index right now in your autopilot all you have to do is you can just refresh the policies by going to the icon and just say refresh policy or you can restart the autopilot as well right so what is happening it will now go try to read up the data it will sync up again and hopefully now I ask the question it should be able to give me the same answer right so I'll just copy the same question last time when I asked the question it didn't have the context so I'll go to the new chat what is session three in this i hit enter analyzing your request right and see it has hit the transitioning to the agentic automation PDF which is now coming from your storage bucket context grounding and now it is able to give you the information that the next session is on 3rd of April please do RSVP for the session if you want to understand all of this topic right and it is able to give me this information along with the sources right so that mean that having a context is important whenever you are talking to any LLM/ aentic automation or AI right so this is how you enable context rounding and all the steps whichever I have shown are all documented are all available so I'll share you those video links and everything you can just watch and enable all of this on your own right so with that I'll take take a pause and then I'll hand the session over to Manoj and meanwhile if you understand this just maybe uh write again understood the basics right because Manoj is going to cover a little more advanced right so maybe you can just comment down understood basics so that give some time for Manoj to open up the presentations and all okay great understood understood cool great so over to you Manoj for the session Great thank you Mukesh for setting up the contest again let me just uh share my screen with you all uh context for context grounding please i hope uh everyone can see my screen yep yes no yes it's visible yeah yes so we'll start with something interesting here uh guys so on the current slide you can see two images here take a look at these two images and type in the chat box what comes to your mind when you look at these images for those who don't know these are two famous Indian films i'm sure people from India would relate to it so just type in the chat what comes to your mind i like somebody told Gajjini and Rajni Roachi confused bot heroes movie I like that no memory one datab memory human versus robot memory loss short-term memory yes so this is all about memory only thank you thank you for your input size so as you know that in AI or in any system memory refers to the system ability to remember past interaction and use those knowledge previous knowledge to improve responses memory also helps AI become more personalized context aware and efficient uh just like we remember what someone just said in a conversation like what we are discussing now so AI uses this as a active memory and like we store experiences over a period of time AI uses this as a long-term memory so together they help AI understand remember and improve it over the time so there are two type of memories one is obviously your active memory it is like when you're chatting with a colleague you both know what you have been discussing for the last 10 minutes or 15 minutes but you if if you leave and come back tomorrow that memory phase unless you wrote it down so this is your active memory for UiPath uh the good use case could be if you are like chatting with uh autopilot for HR and you ask about your leave balance and then about and then you apply for a leave for a specific day so active memory ensures that the chatboard remains whatever is there in that context it just fetch without asking asking uh it from the user again so this is your active memory whereas the long-term memory is like your employee file so it store key details about your role preferences previous conversation so when you return to the system again the system remembers who you are which have just shown you and picks up where you left and the good use case for this could be not shitty but imagine a customer service bot that remembers that you always prefer email notifications or you had the same issue with an order last month so even if you contact them after few weeks it remembers those conversation or takes help from those context and provide relevant help if required so that is the difference between basically a long-term memory and a short-term memory now we'll look at the key differences between a long-term and a short-term memory again so as I said active memory that just lives in the current session it for short-term context it is fast temporary recall and it closes it after the session get ended so it it will not be able to recall once you end the session whereas the long-term memory it is persistent it remembers what you discussed last time it s knowledge it can be accessible later uh accessible later it is persistent can also be updated and deleted example I've already given it to you before so this is about active memory and your long-term memory great is there any question the chat field no great so next topic is again a very interesting topic and that is vector database so as you already know that for decades we have been using traditional databases that have been the foundation for storing all your information so the information gets stored into rows and columns format which is kind of highly organized easy to query and perfect for your transactional systems but now we are the we are in the era of AI and unstructured data so we have got text images videos audio so these are the data that actually doesn't fit neatly in uh neatly into this rows and column format and this is where this vector database step in as I said unlike traditional databases that store data exact data exactly so if you store five the data five will get stored into a database be it SQL be it NoSQL the same data gets stored in the database but vector database store data in a way that AI or the uh can actually understand the meaning behind it so instead of like raw text or images they store information as vectors which is again in simple terms is a collection of numbers so in a nutshell a vector is a numerical representation of your data but think about it what's special about these numbers any idea maybe you can just again use your chat window and type in there why vector stores the data into a numerical representation remember an answer binary okay anybody else indexing great to identify with a unique key machine can understand great each vector is unique for long-term memory right fixed length list of numbers semantic data with positional embedding that's very accurate so you are right actually here thank you thank you for that so basically they capture the meaning so it is all about the meaning of the data so when we search in traditional database we look for the exact match like where select star from table X where column A equals to any value but if you don't use the exact words there you might not get the right result so it it could be like your like search it could be any search but if you don't put the right set of values there it doesn't return you that data but in vector database the search is semantic what does it mean the meaning is again the meaning behind the data for example if you ask AI or your assistant show me people photos of happy people what a traditional database will do it will just again search for a database and will do some kind of a labeling okay if label is happy then they will show you the result but a vector database understand the concept of happiness it can retrieve images of smiling faces people celebrating or even someone enjoying your sunset something like that so that this is called semantic search where it understand your context and gives you the relevant data so on the slide you can see that so we have got different type of uh you can say data images document video audio and with the help of embedding model I'll come to that later but u embedding models but with the help of embedding model it convert actually give you give a meaningful name or meaningful number to your data and then get that get stored into your vector database the other good example here could be uh uh we also created uh a demo for this a few days back so imagine you are using an AI assistant helping a doctor find medical research so again instead of searching the exact keyword the doctor can ask uh find the studies or on how exercise actually improves your heart health this would be tough if you want to fetch the information from a from a traditional database RDBMS but as I said earlier a vector database doesn't just match the word it understands the sentiment or related concept it could be like physical activity or reducing heart rate uh heart uh disease risk something like that and based on all these uh you can say uh information it search the data for you again the data retrieval is very fast it provides more meaning to your search because you don't have to like give multiple u information to your system just pass one record or or one information it will just match which we will show I'll show you in a in a later file and then it will perform the search and a smart AI result returns you the result so that is how you uh perform all your vector searches moving uh moving on to the next slide how does it work so we have seen that okay this is a vector database how the data gets stored but how does the data get stored into your system so again the first step as you can see on the top is uh it's a it's a 2D example so obviously the very first step here is transforming raw data again it could be your text images audio documents your emails it could be anything into your vector embedding and again you can think of a building as a AI ways of understanding meaning like as you can see on that uh image on the top the word king might be stored as four five the word woman is 53 the word banana is 2.5 minus 3 so these number don't mean much to us i don't know what 45 means what 53 means or what 2.5 minus 3 means but uh they capture relationship between the words and the meaning you can see uh on the right so on the left you can see king man woman are categorized into one uh into one bucket then we have got h apple banana and mango these are your another bucket which is on a different path and then we have the football golf and tennis which is again a type of code for that we have got a different embeddings so AI models like open uh open AI embeddings API we have got hugging uh hugging face models or custo you can also train your custom train your network these process input data and converts this into this vector form which you can see on the screen so it gives a meaningful uh you can say index to it a meaningful value to it so once we have this vector embeddings they need to be stored in a way that allows the AI to retrieve and compare them quickly and again this is where vector databases come in so we have got the data we have converted those data into your embeddings and then we have got specialized database like pine con chroma for Facebook there is one more fis so these databases store vectors efficiently again as I said earlier unlike sorry for your interruption like your voice is going up and down can you please come near to your mic something is it better now yeah it's very better thank you thanks a Yes okay so as I said earlier unlike traditional databases that organize data into your rows and columns the vector databases shows embedding in a way that enables fast similarity search so you can see on the right on the top here it has actually basically combined all these buckets into one so I we'll again come to that how this searches would happen but here on the screen you can see that it has divided these or you can see it has done the kind of a bucketization for your data to enable the fast similarity search which we'll see in the next slide again the question is how do we retrieve relevant information so as you can see here king man women are a part of one bucket uh your uh football golf and uh tennis part of a second bucket so if you type sports the system look will look for exact keyword matches but if you don't use the exact keyword uh word it will search for the relevant information here right any doubts here okay so the system compares this embedding with existing stored vectors using similarity metric like like cosine similarity or excluding ance this we are covering in the next slide so again instead of searching for the exact word here AI finds the closest meaning here right if we just go to the next slide here you can actually see the type of searches we have in the vector database so first is your ukidian distance so maybe I can just pull up the image here so as you can see on the right it measure the straight line bit distance between two vectors again if you don't put the right keyword Here it will just search for those vectors find the uh uh you can say the distance find the shortest path between two point and will give you the result and this is best for image recognition or recommendation system maybe um in an image search uh engine you have seen that ucleidian suggestions can help find visually similar images by comparing pixel embedding maybe uh with charg if you just search for an uh dog image or I that is also enabled in bank so you pass a dog image and ask for similarity search so it does this your ukidian distance ukidian search behind the scene and will provide you the relevant information so that is first the second one here is cosine similarity so cosine similarity measure the two vectors maybe I can just pull up the image again so it measures the angle between two vectors instead of that distance so even if two vectors as as we have seen in the previous previous slides even if two vectors have different magnitudes they can be considered similar if they point into the same direction so this is the angle and it is best suited for your text and document search so when searching for again uh budget optimization the system finds document discussing cost reduction even if they don't uh contain those exact phrases the third one here we have is uh manhatten distance so it measure blockwise or you can say it's a grid based system uh so it uses a blockwise distance between two vectors so every vector has got some numbers so it actually calculates those distance grid wise so you can again think of walking through city blocks instead of taking a straight line path again it is a very good use case for the logistic company where they can use this for uh your root optimization when calculating the best delivery options again it could be for logistic it could be uh for uh Indian company like Zomato Swiggy or any uh delivery app like Amazon they also you they can also use this Manhattan distance the last one here is uh Hamming distance again this is not the complete list but I'm just covering both uh like the common one that uh we have been using so it actually counts the number of difference between two vectors again it is best for error detection or uh in the medical field and it is it is used for your DNA sequence comparison where you just need to find your uh genomics to find DNA sequences with uh small variation so this is these are actually your uh type of searches which vector databases perform based on the data that you pass it to your vector d uh moving to the next slide why do we need vector database so as you can see on the right hand side more than you can say 80% or 90% of it uh of your enterprise data is unstruct unstructured again these are your emails support tickets chats images videos and voice recordings again as you know that unlike your uh structure data RDBMS like rows and column format this data doesn't fit neatly into into these systems and the other uh major flaw with the traditional keyword search is it only looks for the exact words if you type hello world it will just search for the hello world like I said earlier if you search for u costsaving in a in a document repository so it just doesn't search for costsaving it can also search for uh expense reduction or operational efficiency something like that to to give you like a proper meaning to because it understands the semantics instead of just matching the whole keywords so which is making it fast the first thing is of symmetric search it understand the meaning it is scalable can handle millions of or billions of documents efficiently the third one here is the speed so again it is it is very fast find it can actually find the most relevant results in milliseconds using similarity search so this is how your uh this is why we need actually vector database and this is how your vector database perform all your searches behind the scenes next we have a demo where we'll we'll show you how to create storage bucket and UiPath and then we can show you how to upload and manage data within there again we'll create a index i guess has already shown you but yeah I'll show you how I created that and then we will go to UiPath Studio web to show you how can you actually use those context grounding activities behind the scene so let me just again stop sharing and I'll move to now my Chrome where is my Chrome okay I'm on a different page or client okay let me share it again is it is it visible guys is Chrome screen visible to you great good so I I guess MK has already shown you how to create a storage bucket in UiPath and upload a document but I'll show you what I have done so far so as I said earlier uh I have created a storage bucket inside orchestrator which contains uh this information so this is my storage bucket and within that storage bucket I have uploaded one file here travel visa guidelines i've asked DBT to generate give me uh a travel visa guidelines in a PDF format and I got a PDF and I uploaded it there so this is first step which I did the second step which I did was again I have to go back to my admin again under admin AI trust layer context grounding as you can see I have created this index with the name of SBO and there's one more SB demo_1 in the autopilot folder i'll show you why I have created two so these are my two indexes i've enabled that uh and u it is visible to me on my UiPath studio web so the next step here is I'll go to my UiPath studio web and I have created this automation for you agentic automation demo which is nothing but a simple screen which contains a text box and a button so this is my demo screen here as you can see it has got a button and a text box and I have created a header content dot button.click file uh on on the on the click event of this button I'm invoking this ZAML directly first let me show you what I've done then I can show you the code behind it so just test on cloud so it is now opening the app here now I'll just type some context here i am traveling for India do you have any pizza file for me okay and here I have given a kind of a prompt to the to this chatbot and I'll just hit submit here so now it has now gone to this screen here so okay let me just click on continue for now this happens every time when I show the demo i don't know why but behind the scene what it does is it will just go to this UiPath activity here this SB demo so we have got this contract grounding search enabled here which will which will just accept few parameters so I've already connected with uh with my openAI account i pass the input text so input text uh text is your uh the text area uh this one so this information will be passed to this text box inside the orchestrator we have got a shared path and uh the index that I have chosen here is SP demo here so it will just do a context search and maybe I can show you some additional properties here so number of search result is is one so you can increase it like 2 3 4 depending on um your needs and then the output will be passed i I've just disabled it for now because it was just uh deducting my balance from my uh open AI account so I've disabled it for now so it will just return you the context here which seems to be not working maybe we can try it again i hope uh this time it should work maybe I pass a different prompt here like that so as you can see here u now it it is working fine so it has returned what uh what are the visa guidelines which I've entered there and this is the source so if I go back to that screen you can see I have got the response back from my context grounding this is not a response from from my generative way activities this is another activity that I'm using here called context grounding search which goes to my uh indexes again this will again convert into embeddings and all search the relevant information pass it here and then you can use your uh geni activities to convert that into a more meaningful response so this is how you can actually set up um uh your uh what do you call that UiPath uh uh storage bucket context grounding and create a chatbot on the fly so yeah that was all about this demo thank you guys time for questions okay so uh Manos there are two questions uh which uh I think uh one I have answered but I think it is good for other people also right so you u you explain about the distances in the vector search right and a lot of people are asking that how is this related to UiPath so okay so maybe some some people needs to understand how this uh searches are happening within your vector database so if you're designing something like your solution for your agents it would be good if you understand this concept beforehand yes that way you can actually save your cost because you don't know how many AI units or or your agentic units or or maybe u your if your vector DB comes up with some kind of a cost because you don't know how much memory or cost they are going to consume from your pocket so for that these information is required and today whenever we are using this UiPath solution UiPath is managing all of this for us right but when you actually when you drive right any enterprise use case you might have a requirement to manage your own vector database right so at that point it is important for you to understand that how this chunking and this thing works so that you can better relate to right so the whole idea was this and uh then there was uh one more question which I just asked that uh I think uh yeah okay and this could be yeah this can be a good interview question as well okay okay so if we are giving something which is Mano this is for you right so if you're giving some something out of context what will happen okay out of context means your L model doesn't know about this right obviously it will not return a response to you right so maybe maybe it is like how you it train your AI models you pass the context and based on context it it actually learns from it but if if your AI model doesn't have the context which MK has shown in the demo um so AI model doesn't have any idea about that topic but when MKkesh passed the data via contest grounding it actually understood and provided the response accordingly so for example raising your kids yeah if you see here right how do you design your agentic solution depend on that how the LLM is going to respond so for example I just go here and I say who is MKkesh Kala right to the autopilot now when I put this request and it says that it is able to give me this information only because this information is coming from here and it does not have any context any information out of it but what happens if I just go to my agent which in case is autopilot and I say that give it access to the Google hopefully Google might have a little more information about myself right so I can just say and then I say refresh and then it will refresh now what has happened is I have designed my agent to give me the response not restricted to my document my environment but also I have given the access to internet and now when I ask the same question it is going to get more details from my LinkedIn from my YouTube and all the other details so to answer your question LLM will respond to you based on how you create the agent if you have asked it to restrict to that scope it will restrict if you have asked it to give anything beyond internet it will give you so it again depends on your implementation right and uh then guys you can unmute yourself and ask questions right hey uh I can see Yeah go sorry prasad Prasad here from Qualicil uh I have a couple of questions one thing I think already asked but I want to go a little deeper into it um suppose when we are preparing the context rounding we are saving everything into vector DB using the tokenization and all right so what happens if there are some unknown words in the while we are trying to give the prompt it should be able to get you the answer unknown words as in it is not a onetoone match right if you would have noticed right when I was writing my prompt right I didn't ask it to give me the actual session details right if I would have just written session two or second session sec second session question still it would be able to get that answer and that is the power of uh LLM if you compare this to the traditional chat bots where you have to actually write the exact word right yeah uh my second question is related to the semantics where u let's say we are feeding multiple languages content to the uh same vector DB then how does it this work because uh we observe right uh some words some good words in one language become bad words in other languages so how does that mapping happens okay so the answer to that question is guardrails right which we are going to cover in the upcoming sessions right so for these things right uh every LLM including UiPath has something which is called a guardrail restriction which filter outs all these kinds of content even today if you go to let's say any chat GP and you ask something abusive or something uh controversial it is not able to give you the answer right so when you implement this agentic AI solution you have to implement some kind of guardrails that is one of the topic in the upcoming session you would see I don't I don't remember the session so to answer your question we have to implement guardrails so that will stop all these kind of things right uh bad languages and all right I think uh it was not about the bad language but uh uh it from one one language perspective it is a good language that when creating the content mkkesh I think Prasad meant that in one language it is uh it's a good word but in another language it might might be a bad word bad word how so that is that is the beauty behind this uh uh you can say indexing it actually understand the semantics actually your meaning meaning of data and give a numerical representation to it read it in any language because it doesn't store your uh your data actually it stores the numbers there yeah now so that's yeah this is somehow relevant uh now for example it looks bit funny but uh orange falls under both fruits and colors right yes so to answer that question right I got your point what you are coming from so whenever you design any agentric solution uh when you go to actually agent builder right which is coming the first thing you tell the agent is the purpose why you are designing the agent right so for example today you are building an agent you have to give the background of the agent which means you have to give the context so for example take an example of the origin I am a paint shop so I will write the prompt into the initial when I'm building the agent builder which will come into the upcoming session you will see I'll just say that my agent is a paint shop where I am dealing with colors now when any user comes and write orange it's not going to be treated as a fruit it's going to be treated as a paint/color does that answer yeah fantastic awesome uh I have one question that uh currently I'm working with a you know a banking system so they have their confidential data so I need to to some use NI model based on what you have explained uh that the models that whatever we select those models those will be online so banks don't prefer those so they want us to have an onrem LLM or whatever the model whatever the requirement is let's go with an LLM so when I'm going with onrem LLM so what are the procedure how will I selecting like what kind I can't select the open AI offline model you know it will require a large amount of you know a huge amount if we talking about it so client will straightforward to reject that solution so how do we suggest that we choose an LLM uh for our specific task like if I want to do an email classification that my customer sends me an email it can be like uh from India so they they like in English or they can be in Roman Hindi you written in English but so I need to choose an LLM so how would I choose a specific for that purpose okay so today agent builder and agent is available on cloud right having said that UiPath has capability to integrate with any LLM when you talk about the on-prem LLM you have uh you might have used heard of llama which is from meta right or you might have heard of something which is called inflection so both of these are the on-prem LLM which means that the LLM sits into your company environment on prem right you host the LLM on prem you train it on your data and then you expose the APIs right when I say expose the API you can do it as a connector or you can directly use an HTTP request now wherever you want to implement it instead of using that LLM and all you just hit the connector so for that you cannot use the agent builder because today it is available on cloud But you can do it by the traditional way the way we used to connect to any other system just an API call oh okay okay so I'll just try to use so there is no like is a function or keyword for that like if I'm using llama it won't support me like I can directly connect to llama without using an API or something like today lama is not there because llama is installed on your local machine yeah exactly yeah yeah okay so thank you hey MKkesh hey MKkesh this is Narish hi Narish yeah uh I'm working on a project in that I need to reduce the tickets of the support right and where I found okay user is having some issue in the uh training I mean they don't have uh knowledge about the process and they have uh uh they don't know how to deal with the application and for there the application team that support the application has the KB articles so now I'm trying to understand how I can use the autopilot Let that can hit those KB articles and find the answer for the user okay two ways to do it right if your KB articles are not changing very frequently which I believe are not changing for any enterprise right you can download all of them and as myself and Monoji uploaded that documents to storage bucket you upload your KB articles to the storage bucket right you enable the context and then you have a front end in autopilot which just hits and gives you the answer right let's move to the second scenario where your KB articles are not in a form of I would say documents which can be downloaded and they keeps on updating autopilot has an option to hit the existing processes as well you I understand uh I believe that you are an RPA developer or you have an background of automation right so what you can do is you can write an automation simple plain RP robot which goes to that uh I would say website extract the information put it in a structured format and upload to the storage bucket refresh the context and it is available back to the autopilot both the ways depending on how you want to do that right so in that mean uh I have to upload my KV article in as I intex in the bucket and I I can write the cont uh context yes so that would be a multiple context uh because that KB article related to uh mean different problems no you can have multiple indexes and then you don't have to specify which index right so for example when I was writing that prompt right i didn't specify which index my other solution have let's say 100 indexes that's the job of autopilot to identify the correct index okay okay you don't have to do anything yeah if we have something uh like that can be automated based on the context we can uh create a agent or a robot that can kick off and uh fix this issue yes exactly and uh storage bucket also comes up with APIs so that uploading part can be also done with the help of automation which you can do let's say uh every 15 days I want the articles to be refreshed and all can still do that great thank you thanks hi Mkesh on the side just uh guys if you can just raise hands I think that would be easy for us yeah know go ahead yeah thank you just to add to Nar's point so the use case which he suggested at enterprise level so what you like what solution it will be I was just trying to mimic it so it will be like all the users who they want access to the KV documents they will need to have assistance on their machine and over there copilot uh they can go to co-pilot section and in their natural language they can type it the query and we can have any number of KV documents have that have that indexing done at our storage bucket and map it to our uh agent and then it will be done right yep yes correct and I guess the other good thing here if you don't want to use autopilot work you can create a UiPath app and Mhm so I was thinking that only key uh what will be the front end is it like we need to have uh user need to have assistant on their machine or or app can do that so it has to be a front end any front end as Manoj mentioned right it could be apps it could be autopilot you can build your own interface connect it to that as well so provides you that flexibility okay thanks thanks thanks man okay then I have Ranov yeah yeah hi I'm Mkesh uh yeah uh great session today uh so uh just wanted to ask like can we uh with the autopilot can we connect like uh like you showed you can connect to Google as well for the as an information source so can we have any other website uh as well as an information source uh like a c like a different website altogether yeah so we have something which is called web search activity which is a part of your generative AI activity right uh so gen activities are available there as an integration services you yeah uh yeah I was asking actually in uh in a perspective like uh whether we can have it as a context grounding kind of thing yes yes absolutely we can have that right web web search web search is the answer yeah okay and uh can we have any database as well as uh one of the like uh okay so today the direct database is not available reason for that is the vector right because LLM have to work on a vector and I cannot use Oracle and all right having said that you can always write an UiPath automation right which connects to your Oracle SQL SS SMS and all and then periodically you just use that database to fetch the data and upload the vectors okay okay thank you thanks Rona Priyanka yeah hello sir actually I have a question related to context grounding i'm trying to build a model but always I get an error related to tokenization but uh if I just try using a chunk then the model don't provide efficient output after feeding a PDF to a model so how can I just solve this error i'm trying to achieve here yeah actually I'm building a model which can analyze a PDF and give an output related on that PDF but whenever I try and tokenization like API open API and all those case whenever I sorry sorry model means your custom model here like you're creating some kind of a model on your machine some local model or you are training your model actually I'm training my model okay yeah so your embedding is not working this is what you are saying yes uh like whenever I'm trying uh open API or is hugging face or is GPT4 and all those things I get an tokenization error and if I'm not using a tokenization API and all those things just using in chunks then I'm not getting a efficient output uh that's the problem with the max right yeah so max token I think uh are you using the free version or are you using the paid version of it uh sir if I'm using a free version it is not working yes yeah so basically uh for all these LLMs right I haven't tried hugging face and all but at least for GPT I can say every LLM the free version have something which is called a free kota right so for example if today all the free users are hitting that thing you will get into that tokenization thing right so if you're building something like this right so the best way is to create token yourself which means in other words create the embedding yourself manage your own vector database and then manage your own LLMs okay sir so that would be the answer okay sir thank you okay has also got some limitation with your file okay thank you Priyanka sushila yeah hi bkish So in the last session when I attended Ih learned like how to create agent and everything so I built a one agent uh it is working fine in that uh back and it is means I'm also able to publish it but when I'm trying to run it from orchestrator as a job just like other RPA processes we are working running it is not working it is always giving me faulted status no but what why it is getting faulted right that you need to figure out yeah miss I just want to know can we uh publish our agent process as a normal process to orchestrator but why would you like to do that uh actually I want to use that agent outside of orchestrator ah okay so in your UiPath studio uh you have an activity called run agent okay yes drag and drop that activity and that activity you would see all the agents which you have created now when you publish that solution and when you run it from orchestrator that will internally trigger the agent yes that that I have also tried that but the individual agent is working fine but through run agent activity when I'm linking that agent it is suspended to that state only see suspended means that you have used uh persistence activity in your agent right when I say persistent it is humans in the loop so one of the uh component for agent is humans in the loop where the agent is expecting some of the input and that's why the agent goes into the persist uh sorry suspended state waiting for the human input till the time the us human provide an input the robot is occupied doing something else as soon as you provide the input it will be resumed so suspended if it is suspended you previously mentioned faulted right suspended mean it is waiting for the user input you might have used some persistence activity there that's what suspended it suspended it is yeah from like uh UiPath studio or web studio it is in suspended state but but for that I will check that uh mean how to check that it is persistent or not uh it will come into your logs right orchestrator locks that why it is suspended maybe you can run it in the debug mode and that should be yeah through debug mode actually uh it is suspended and it is not never executing i went to orchestrator proc uh uh sorry agent orchestrator in that place it is like uh stuck in agent and okay I think then sila sorry to cut you there right so uh for the I think uh these kind of issue right maybe we can put it on the forum where I can try to answer you can send me the link right and we can stick to the questions to this session only yeah right yeah sure thank you thank you okay uh Mohammad Yeah just have another question regarding the onrem so I'm just trying to saying that how would I choose a specific LLM so I understand that I'm using llama I'll have to use an API to do that but uh you know with my llama I have multiple options that whatever kind of LLM I'm using so how can I choose a specific LM for that purpose is there any uh you know guide for that i know it's not the topic for today but I just want information that how is there any guide or something that from where I can learn that I can understand that how should I choose an LM for my purpose based on my machine specifications there is no guide for that but it is simple right so how much how many parameters the LLM is trained on right so for example GPT is trained on 1.3 billion parameters something that's why when you ask a question it is able to give you the response clearly if you install llama locally you would see that it is not able to give give you the answers more accurately as it was supposed to do right now depending on your again requirement uh if you install llama you would have to train it on this otherwise there are other LLM which has a different function uh different uh I would say uh different LLMs have different properties so for example if you uh see this inflection right they say that they are more uh humanentric and this is more human uh I would say more human centric LLM it does not give you the responses it is uh more towards the emotional intelligence so agents have different kind of intelligence someone has uh action question someone has intelligence question someone has uh EQ IQ and all these things so what kind of industry you are trying to build a use case for so for example if you are building something for healthcare you want the LLM to respond which is more empathetic whereas if you want to build something for a financial you want it to be more decision-driven that would be your starting point hope that answers okay we'll take that as yes then okay so uh just sir thank you i just another question about regarding the writing a prompt about those things that that how can I improve like those prompt writing skills cuz you know every time you write a prompt the LLM want the specific answer that you looking for so those prompt writing skills that they're also important for in context that we want to use some kind some any kind of LLM or any kind of agent take AI or something so we need to learn that how those prompts are yeah prompt engineering prompt engineering yeah okay so does UiPath provide something like a course regarding that it's not a course which is available on UiPath but if you see the UiPath agent builder right so they have given you some of the best practices to write the prompts so best practices are there already maybe when whenever we are covering the agent builder session that we'll cover that as well okay okay thank you builder you will get something hashtags hash yeah delimters something like that where tell you okay whether you have written the right prompt or not like Yeah uh okay thank you thank you okay guys any more questions guys i see a lot of chat uh you guys uh I think uh Adriano you can unmute yourself and ask the question you have a long question single agent okay man you have read that you want to answer that or Adrian if you can unmute and you can ask the question yourself as well it's also fine yes I'm here hey hi thank you um I'm saying if you will have a demo orchestrating um many steps in a workflow with many human or automated decisions in in every step I I need to call u another or other agents as um as manage uh show us so is is it is possible and and I I think is it's possible um but very interesting not not chatting with only an agent so I I'm I'm viewing a long-term uh workflow in parallel in parallelism I I'm chatting and using agents to solve the many steps workflows so I I take uh faster decisions in every step but I need to preserve the longterm workflow i'm a specialist in I'm a specialist in BPMS and business rules i'm very interested in technology and now nowadays with UiPath using an orchestration in long term um I'm very interesting in in uh have the fusion the fusion of the long term and the shortterm and agent okay short answer to your question is UiPath has got something which is called UiPath uh MRO right is maestro which is also known as the agentic orchestration i'll put the link this should answer your uh question right so it is it is coming right yeah Mano your your mic is not working i guess I can come along with my mic sorry i was just saying that yeah with master you can just define your workflow with agents with Yeah board so you can just connect everything together and run it in one excellent yeah yeah yeah i guess in next call I'll just change my mic again thank you thank you thank you i guess we have also got a question from Lata uh can you just unmute and ask your question if you're there okay maybe I'll ask the question manage on behalf of Lata right so it says that I have uploaded a sensitive docu document to the storage bucket and did all the query and llm right there is an other person in my organization who uses the same orchestration orchestrator right now would he have access to my storage bucket since it is a long-term memory it will remain my sensitive information and uh it can leak my information how ethical are the agents okay so that actually depends uh how you're actually going to define your automation here if you're using autopilot Obviously that will go into your shared folder so other user won't have access to your uh uh storage buckets but if you are saying okay no I don't need to use autopilot here I'll stick to um UiPath apps so maybe with the at the runtime you can just set up okay for this user this information should be available something like that but for personal user I would recommend that it should only have access to that shared portal only so you should stick to autopilot but for generic information yes UiPath apps you can go for it and uh just to add to that UiPath has also got something which is called PII filtering which is available into your UiPath generative AI pack where you can actually hide your sensitive information by just using a single activity so you don't have to upload your sensitive data right so that's called PII filtering that also you can do right and I guess we've got one more question from Gotham do we have Goautam on the call maybe MKkesh you can just write it and we can provide an answer uh I don't see that question man what is that goautam said uh uh he has some testing scription tka and tska is a model based approach application and the file are in it their own format now he wants if he can upload the Tska files in storage bucket and use context rounding to build the same test scripts in UiPath using uh autopilot okay see uh for this you your autopilot is not the answer for that right autopilot is a conversational agent Gotham right which is giving you an opportunity to ask follow-up questions and all your requirement is more kind of a automation requirement top of that UiPath also have got something which is called UiPath test suite they have also introduced something which is called agentic testing so this thing fits into agentic testing can we do with this approach the answer to that question is yes but should we do it the answer is no because we are over complicating the stuff one simple way could be that you have uploaded it to the vector database and then from UiPath you just write an automation to directly access the storage bucket and get the data right going to autopilot because autopilot is a conversational agent help helping you to answer the questions and not creating something new and when I create in autopilot it entirely depends on the prompt right so chances are there when you write a different prompt it might give you a different option so here you need to create an automation and not create an agent uh sorry autopilot solution and also I would request you to just explore the agentic testing which is now available into auto uh UiPath as well so that should That should answer okay i think Manoj we have covered everything uh you your mic again went Manoj yeah sorry i guess that's all we have for now thank you guys for joining the session again so we'll see you next time same time okay and just a request guys if you enjoyed the session right feel free to post your learnings over LinkedIn tag myself Mano Rohit and happy to amplify your post and see you in the next sessions and again sorry I forgot to tell you one more thing if you still have got any doubt maybe you can use forum.ipath.com uipath.com uh for your questions so you can just post your question there tag agents and whenever we get time we'll make sure that we'll respond to that questions right again the same question where we find the recording the recording would be available on the same page I have again shared the link click on that it would be available always there create an agent for the team right great guys so thank you so much guys for joining and have a good rest of your day see you in the next session bye thank and for the wonderful session thank you guys bye bye thank you very much