so good morning everyone it's good to see you again and um I guess so far we talked about uh databases we talked about Java we talked about web programming now it's time to go ahead talk a little you know regarding data structures probably algorithms and so on and that is the reason we are here right so let's just get started uh with uh data structure what data structure is or before that what all we need to know before we start with the data structure what all we are going to see in a module and then uh we will actually get started with the topic so very first thing what is the prerequisite of the module I guess I already typed it on your WhatsApp group uh what is prerequisite of module is Java programming language so I'm very sure you people had you know extensive work onto the Java and you should be very comfortable probably this list I have already shared with you something that I said that you may not much need into the when it come down to the data structure algorithm is like inheritance polymorphism or these kind of concept so we need the fundamental of OB Concepts we need uh you know the mainly language fundamental in the sense variables FS uh Loops switch cases you know these kind of stuff we need it often apart from the other ones right so I'm very sure you must be knowing as I said that this particular module will be like more or less the practical oriented it's like uh we'll be having more focus on actually doing the things than just knowing the concepts and the language of doing probably for your batch is like Java programming language so it doesn't make any difference because when it come down to the data structure so it is language agnostic we said so whether you have done in C++ whether you are done in Java whether you want to do it in like python whether you want to done like any other language it is absolutely fine the data structures always remain the same yesterday someone asked me the question and that is the reason I believe that I should also answer that just for the better Clarity of like everyone there was a question that when we talk about Java so Java has got something like a buil-in collections you go to the python or python has got its own collections you go to the C++ it has got like a STL you go to the C it has also got its own data structures so the question is when the programming language already have kind of a link list available when the programming language already have got arrays available a programming language already have got a library where the stacks and cues everything is available why we are learning it once again or why data structure is kind of a separate module if you ask me they are like a couple of reasons a reason number one is the very first reason I would say that the very first reason is like your thinking AB abilities your thinking abilities the data structure module is one probably where we consider few really small problems and few really big problems a small problem could be like add a node into the link list or probably a kind of big problem that find the uh what the shortest path between two points in a city something like that so given a problem statement how do you think upon it so what are the major mechanisms or what are the major uh thought processes behind giving any problem statement like a thinking in the algorithmic way of thinking like a first thing the second good reason is that a lot of time people keep complaining that so we are not too good at coding I always believe that data structure is like one of the module where you can be really good at coding where you understand the algorithms so you spend a little time in understanding algorithms you spend a little time understanding algorithms what algorithm is how algorithm is or like how it is going to solve and then ideally ideally then you implement that algorithm into your own way into your own way so people who always consider that sir I'm bit weak into the programming this is always ideal like for example you learn a selection sort so you don't Focus onto the code of a selection sort you first Focus onto the kind of algorithm of a selection sort you focus on algorithm of a selection sort you understand its paperwork you do the paperwork on your own you make yourself more comfortable and as you are comfortable on paper that I understood how algorithm is working then you think of how do I convert it into a programming language so programming language again now programming language of your choice so whichever language that you find it good so you can right the third thing uh fourth thing probably why data structures are there into your syllabus the one more reason probably I would would say that it is it is it is it is wait for a minute it is interviews because it is very common that in interview you have got like a questions on like link list questions on like a sorting questions on a searching and then again you have a question so why these people are asking us are these people writing all all the way you know down the line so what we actually take what we actually use is probably the redimed link list the redimed link list class is there in Java redimed list class is there into the C into the C++ so things are R made available but again why in interviews we are mainly focusing onto the data structure reason is again same that interviewer want to know that can you think logically can you think like whatever problem statement that you have got are you able to convert it in algorithm in a flowchart and then if you are able to convert an algorithm are you capable of converting it further into the code is it possible for you now this is what again interviewer always ask you so when it come down to the interview and probably you know interviewer is asking you okay go ahead write a quick s if any person has written a quick s directly directly in the sense without any kind of paperwork the likely chances are that that person is out of interview sir we are correct yes you are correct but interviewer is not interested in knowing that okay whether you have mugged up quick shot or not he's interested in what was your thought process behind that entire story so how exactly you thought of how exactly you taken like a peod then what kind of paperwork that you have done what logic that you have put and then are you able to convert that logic into a piece of code so anyone who is saying that okay this is like algorithm and this algorithm I have just baded and I have just written there there are likely chances that in interviews you fail so I'm saying that what we need to take care what we need to focus on is obviously we need to understand given a problem so first thing we need to think second thing we need to put it in algorithmic way that how we can try to convert it into a computer algorithm and then from the algorithm how we can convert into the code so in my case uh in my um opinion these all three points are important and that is the reason we are learning data structures so data structures we are writing is not for computing the Java framework Java collection framework no don't try to do like that we are here to understand it right and are we able to write it on our own that is something we are looking for I guess that gives you Clarity why we are learning this BL module even though Java has got buil-in collections or any other programming language has got a buildin collections okay what all we are planning to learn into this blog course is definitely we talk about some conceptual stuff like uh time and space complexity yes definitely we talk about linear search and binary search kind of mechanism we talk about like recursion we said recursion is something that you must be already knowing but still still uh we will again go through the recursion a reason is bit different because this recursion understanding you also need it for one of some Advanced uh stuff so we will have a quick recap of what is recursion and then how we can use recur for solving certain kind of problems then we will talk about like basic sorting algorithm like selection sort bubble sort insertion sort or stuff we will talk about the link list link list Concepts link list implementation we will talk about the cues we will talk about the stacks and even the applications of cues and stacks we will talk about then we need to talk about trees that what basically the binance search tree is or how it can be implemented and then more or less conceptual stuff we need need to also discuss uh what is Hep or probably what is Hep sort but obviously uh Hep sort is kind of one of the advanced sorting algorithm there are like other sorting advanc sorting algorithms are also available like you say quick sort or mer sort yes we will talk about that we also have got something called hashing hash table I'm very sure in Java you already use hashmap but even though Java gives you bid in hashmap I want to learn okay how this hashmap is like inter implemented what is the technique behind it what is the logic behind it can we write our own hash Maps yes that is what hashing or hash table concept and finally we will go onto something like graph Theory and not only graph Theory even graph implementation now you ask the question how many days it need uh to be frank I just uh recently we completed for the February batch uh you might be knowing if your friends are there and it took around 8 days to complete obviously uh I cannot teach it at that short span but then we will my plan is that we will go for nearby 10 days 10 working days where we will talk about all these codes and algorithms but then apart from that something more as I said that it is about thinking abilities also so there are two three very common techniques of solving the problems the problem solving techniques what do you call it as a problem solving techniqu techniques as I said that we will look more practically but still still you have to know what these techniques are so there are two three most popular techniques are there the first technique divide and conquer I'm very sure you must have heard of this technique and this technique the divide and conquer technique is something you call like a recursion yes it goes around the second technique I can talk about is um probably greedy approach greedy approach or greedy algorithms of solving the problem and the third one is soled as a dynamic programming dynamic programming and yes we will be focusing on to all those as well uh there are several yes brute force is there or like many other are there uh something the most popular the most straightforward algorithms uh most of the algorithms they fall in this kind of category so yes apart from those you know more of practical stuff these are the conceptual ideas that we want to get and obviously not only conceptual ideas probably conceptual ideas is like hardly for one slide but after that we need to implement in a program and then we need to visualize oh what exactly it means correct H so what I was saying is that uh so nearby 10 days uh it will take where we can go through this module and we can try to learn all these Concepts as you must be knowing and so as far as exams or like evaluations are concerned I guess by this time you know the pattern the very first thing is your theory exam which is expected to conduct at the end of the course what we usually call it as sedak course end exam right and uh you expecting it somewhere into the March right this second one is your lab exam again like a 40 marks uh with a combination of like hacker Earth or like some sort of problem what is that file upload kind of problems but I believe that at this time there will most of them it will like a hacker the best kind of questions so 40 marks and you can expect the exam to be on near by 10th of January you can Mark a date so like instead of like asking every day so exam and when I should start preparing so better you mark a date I guess it is 10th of uh January uh somewhere I guess it is Sunday nearby so mostly it is planned like that and the third one is probably obviously the internal exams there will be some of the assignments uh check as well as there will a quizzes and etc etc so like uh again that will be like somewhere at the end of the module you can expect it to be like 11th or 12th January nearby so I told you that this will be something our module plan this will be kind of evaluation what all we are supposed to learn I guess it is enough of introduction and uh we should really get started to understand what data structure is basically obviously I not written a very small small concept that what is data structure etc etc but yes they will follow all the way and we will begin right from a very fundamental question what do you mean by data yeah getting back so what is data structure if you ask me in a very simple language I would say that data structure is structure of data what data structure is a structure of data this is probably you know kind of very much what I can say this is kind of very much uh very diplomatic kind of definition where you simply say that data structure is a structure of data but exactly what you want to talk about as a data structure basically what I want to talk about data structure is that when I say structure of data it mainly covers two things the number one how the data is organized in memory how the data is organized in memory how the data is arrang in memory so like kind of continuous memory or kind of uh link list kind of node each node pointing to another node hem or something different something that it is organizing data in memory and the secondly I can say that processing the data a secondly like a processing the data whatever data is available you just do not want to see the data you want to do certain operations on that BL data so again how the different operations to be performed onto that PL data so usually when you say that I'm learning data structure and algorithm module you are trying to focus on how how a particular data can be arranged in memory number one and number two how the execution can be done on it again in both the lines I should be using a word something called as efficiently so efficiently I'm talking about efficient storage as well as efficient processing of the data so so what are different different data structures that we have got or different different data structures that we have got so we can start talking about there are again this is not really the you know bookish one but uh I would say that this is a rough division you can say there are certain data structures which comes out to be like very normal very common and you know usually by default available in most of the programming languages however there are certain data structures which are when I say advanc they are quite application specific and most of the time you need to build them by yourself getting back so you talk about we are got like a array so you ask the questions AR is the DAT structure so we have learn array in almost every language yes you learn array in every language but trust me even array is a DAT structure where you say that the data is stored in a continuous location so array itself is a fundamental data structure and you will not believe probably it is one of the most commonly used data structure which you have already used into almost every language that you done but you never know that oh it is a data structure right going ahead you talk about like a link list another very popular kind of data structure that we deal with then we talk about stack we talk about cues these are we said that like a utility data structures utility data structure meaning by not for saving the data but to process the data so they are not for the storage they are for the processing and the intermediate data will be saved into that so like a stacks and cues you continue further and we are got like a trees trees bit as I said it comes down to the little Advanced data structure so we have got like a trees uh for the optimize searching that is like a main goal of a trees but there are other advantages as well some more specialization I can say that it is a heap after you talk about tree you have to talk about the Heap and then we can also go go ahead and talk about a graph now these are data structures which are not available into most of the programming languages I do not say all of the programming languages but I say that most of the programming languages you may not see a redimed tree is available or redeemed uh graph is available yes Heap is available in at least few data few languages that I know like Java but I'm very sure you may not have worked on that like for example Java has got a concept called a priority que the priority queue implementation of a que that internally uses kind of a he so but that is the reason I just consider it as like Advanced data structure and this data structure usually you need to build it by yourself so with this but what basically the data structure is what exactly we need to focus when we talk about data structure so there is word that always people use saying that data structure is ADT what is ADT ADT is it Advan or something like that no no not at all Advance ADT stands for abstract data types I'm very sure you come across the word abstraction during your op Concepts so abstraction yes abstract data type what is abstract data type where in op there is like a foundation principle you always say that what is there inside the object what is there inside the object what kind of data is inside the object you do not bother but what do you bother you bother what all operations that you are providing so you are not worried about what is hidden behind it you are always worried about what interface is given so when you talk about like a watch you talk about a watch you do not bother what kind of machine is used what kind of chip is used in or whatever I said that it hardly matters what I'm worrying a lot is how do I how do I use that watch how do I see the time how do I change the time now these are the kind of stuff that we are trying to focus on correct so when it come down to the like external implementation or when it come down to using data structures we always say that it is abstract data type and that is what you people have done in Java so in Java you always say that there is array list now there is a array list there is a link list there is a vector and you found that almost all have got all kind of functionalities they are giving you kind of similar kind of output so you always say that ke there are certain functions that I need to execute so I need to add a data or probably I need to remove a data or I want to check whether the data is available kind of contents method and there is a method to search where is the index of method so in Java collection they have given you the buil-in methods so you do not bother about how it is created internally prob we never seen that whether they are using a kind of a node structure whether they are using a kind of array structure whether they are using something different who cares what is important important is that what add method does what remove method does what contents method does what list iterator does what index of does so we should be knowing which all parameters to pass and what value what results to collect that's it this is what all we look for we never bother about how the implementation is done by the Java people and this is something I'm saying the abstract data type so when it come down to the data structure you always say that it is abstract data structure we are more concerned about the operations done on that then then we are like concerned about we are concerned about how it is implemented behind the scene to example yes absolutely like for example you talk about array as a abstract data structure when I say array as abstract data structure which all operation the array should have AR I believe that array should have only two major operations only two major operations one I said that get element at a index get element at a index and second thing is a set element at index these are I would say kind of a primary operations that AR structure should provide the basic minimal operations obviously Now using these operations on the top of it there can be even advanc operations the advanc operations like searching in Array binary searching in Array sorting of array correct these are more or less kind of advanced operations on the top of array but the very basic level operations are very simple getting element at a given index and setting element at a given index so you say that array is kind of abstract data structure which enables you for something called as a random access something called as a random access so you want to access nth element directly and that is what all you look for now you go go ahead you talk about another data structure let's say probably you must have heard of Stack as abstract data structure stack as abstract structure which all different operations are to be performed on a stack I always give example uh all operations that we need is that kind of a push push element onto the stack the second we should be able to pop the element from the stack third probably I can say we can pick which is the top most element of that topmost element of that and if you at all need the fourth one I can say that is it empty is stack is empty or not empty that's it now what is again the primary behavior that you looking for a stack the primary behavior that I'm looking for a stack is last in first out so I hardly bother whether the stack is internally implemented using aray whether the stack is internally implemented using link list who cares or whether you used tree or like graph I don't bother what all I bother is that the stack as a abstract data type we just talked about over here so what functionality is been provided what functionality is been provided and on the parallel line I'll take up one more example not all data structures that we will be discussing on a day one uh but you go ahead the another one you can say that we can talk about a q as abstract data structure Q AB data structure you find that it comes with the same way what is that push functionality pop functionality pick functionality is empty functionality obviously with the different int what is that here you look for first in first out isn't it yes absolutely so I'm saying that this is nothing but abstract dype so while you implement obviously you need to think definitely I need to think and definitely I need to implement it accordingly but the minimal requirement yes we should be knowing in advance and that is the reason we that data structures are abstract data types and that is the reason you will also find that the most common implementation again I'm not saying that uh it cannot be done in other way around but the most common implementation of all data structures are primarily done in objectoriented fashion objectoriented fion so you go to the C++ you go to the Java so it is most common that people prefer making the data structure implementation in a op manner than in a procedure oriented manner very common because the abstract data type this concept closely resemble to the op Paradigm isn't it so that was all about like a quick review what data structures are what are the like kind of rough classification what do you mean by data structure as abstract data type as we will actually start working actually start working in the sense let say stack or we will talk about like what are the ad operations and then we will start implementing it when we start discussing about link list we'll again talk about the Ed operation and then we will start discussing onto that so every time you take up one and you start discussing it further now that is basically the idea then you continue further now we already seen what are different data structures that is all right but I told you that when I say that I want to organize the data into the memory when I say that I want to process that data and then I used a word I use a word saying that I'm looking for everything to be done efficiently but you know the question is what is definition of efficiently what do you mean by efficiently how do you say that whatever that you are doing is efficient because you know it is like a human nature that whenever you do something you always believe that whatever you are done is correct isn't it so you know uh you come down to the like uh there like a lab exam there lab exam lab exam you have done something and you always say that you might say that the question is wrong but because I always do you know correctly people always have got a thought process how do I actually talk whether it is efficient whether it is not efficient like for example for example I'll take up some simple example which probably you can understand again uh a bit different you know when we start with the module like a database there was a story was different story was different because database was like something entirely new to everyone so like what exactly database is so probably from there we need to start and then we need to you know discuss from there step by step till advanc topic but when it come down to the like module like data structure we understand that we understand I understand that it is kind of a prequisite of a course so some basic data structures you already know you already aware of and forget you people recently you people learn Java so you might have even revised some of the basic concepts so obviously I will keep that in mind when I'm delivering this pession so situate that you also keep it in mind and retrive it as early as possible that will be really great so coming back to the point so you see that so I'm creating array of 10 elements so what is efficient so my AR is taking for 40 bytes is efficient or is it taking 20 bytes is efficient or is it taking 10 bytes is efficient now you people understand it very well that array may take 40 bytes array may take 20 bytes array may take 10 bytes array of 10 element the same array of 10 elements may take the different different size depending on can you just uh complete the statement I said it may take different different time yes it depends on your data types absolutely so somewhere someone is saying that I'm creating array of integers so four by integer it will take 40 bytes two by short variable it will take it will take 20 bytes character variable probably it will take the 10 bytes itself so what all the point that I want to make it over here is that it is very much dependent on a requirement you cannot say that sir I created array of 10 elements so my array is efficient then probably your array because your AR is taking 20 bytes and my is taking 40 bytes the problem over is that you might be trying to solve a problem where the short variables are sufficient and I might be solving such a problem where I need a kind of integer variables so that is not really the measure that how many bytes it take to store number one the secondly not only about this there is something you know architecture specific stuff is also there so sometimes you might have seen that you know some architecture size of int is different and another architecture size of int is different like like right right now we are looking on x86 platform we find that size of int is 32bit but the same thing you do like older 8086 or for that sake 80186 or 80286 machines at that time size of integer was 2 byte or probably you go on like a embedded platform like AVR size of int comes out to be 2 by so what I'm saying is that even though by saying you say that it is like a integer L that again might have the architectural dependency I hope you realize the problem that you cannot always count the efficiency of storage based on based on how many bites that you occupied and same is a problem with the time as well let's say that I always say that like for example a certain algorithm let's say XYZ algorithm running on my machine running on my machine is taking let's say 10 millisecond but probably another algorithm that you are running on your machine the for doing similar thing let's say one sorting algorithm I'm running on my machine it is taking 10 millisecond but the same sorting algorithm probably you have developed some different sorting algorithm and it is taking 15 millisecond so do you believe that the 10 millisecond is faster one I repeat one algorithm is running with the 10 millisecond time the second algorithm for similar sort of data similar amount of data probably it is taking 15 millisecond to can you say that 10 millisecond is efficient one do you believe that yes you can say that oh how come because what I'm saying is that the machine that I'm using is kind of cor i7 machine and the other person the machine that he is using probably the Pentium machine is it possible and now in this case now in this BL case I hope now you visualize that so on paper or probably by looking at time you can say that sir 10 millisecond is faster and 15 millisecond is slower what take on paper you can say but what about the architecture on which the execution is done what about the like computer type that you are using so like someone is using a machine of let's say 1.5 lakh someone is using a machine of let's say 10,000 rupees again it's not only architecture dependent it is also even the machine configuration dependent whatever I was discussing right now whether it is about space whether it is about space whether it was about time this kind of analysis you would refer it as this kind of analysis you always efficiency analysis this analysis you always say that exact analysis this is exact analysis and then you ask the question so what do you mean by exact analysis the exact analysis of a space probably you can talk in terms of how many bytes that you are taking for executing certain algorithm or storing that kind of data and the second one where you talk about the time the time machine time or the number of CPU Cycles you can say millisecond or microc or something like that so you are talking in that terms this is referred as exact analy is but this exact analysis most of the time it has been observed that it is useless why it is useless the exact analysis is found to be useless why it is useless because the things will change from architecture to architecture things will change from machine configuration to machine configuration to Sir solution the solution is that exact analysis we always go for something called as a asymptotic analysis asymptotic analysis now where where you always talk about when you always talk about now how many bytes me I'm saying that over here we will talk about let's say unit space we will talk about the unit space required for the storage we do not talk in terms of bytes or for that sake for that sake asymptotic analysis for the so I'm talking about usually how many iterations iterations in the S how many times the loop is getting repeated I'm talking asymptotic analysis so we have got like exact analysis or asmic analysis so you need to understand that usually when it comes to data structure we always discuss about the asymptotic analysis we do not discuss about the exact analysis is one so so what basically Astic analysis is how it goes and etc etc let us take a look at the very first thing yes obviously we want to talk about is a space complexity first and after that we will take a look at what is time complexity so what is space complexity space complexity I can say that it is a unit space required to store the data and the additional space required to process the data so usually when it come down to the space complexity there are two components involved please make a note of that the first component I say is the input space and second thing is let's say auxiliary space I'll give you example I'll give you example suppose that you want to calculate the factorial you want to calculate the factorial a very simple stupid example I know so you want to calculate the factorial to calculate the factorial what you need you need a number now you need a number to store that P number you need some space so that space you can select a input space but the second thing to calculate the factorial I guess you need some extra variables some extra variables to occupy the result some extra variable to go through the loops so extra variable use Loop variable or result variable or something like that I said that it is a auxiliary space it is a auxiliary space so we have like input space and the extra variables that we might need during the processing I call it as auxiliary space so you call it as a space complexity you continue further you continue further so what is different space complexity uh you know mechanisms are there I can say that it like a o1 o n o n Square so what exactly o oh how do I read it I can simply say that it is something called as a order of technically it is called as a Big O notation but I always say that it is read it as like a order of the order of order of either you say order of n or you say order of n sare or sometimes you say order of one so what do you mean by order of one the order of one simply means it is a constant it is not changing with respect to something I'm hoping that factorial program you can imagine on yourself and if you're imagining a factorial program by yourself you can always say that my normal Loop factorial calculate then in that case the what is input space is like one integer so that space is required usually space complexity we are like more bothered about auxilary space the extra variables that we need so don't you think that you will always find that the loop variable you need one Loop variable you need one result variable that's it now it is irrespective fact would say that the extra space extra space that is required is going to be the constant it is going to be the constant so you see that in that plug case your auxiliary space for the factorial is kind of O of one it is not changing it is not changing with respect to with respect to the number whose factorial you want to calculate but I'm very sure if you ever think of factorial using recursion now factorial using recursion when you're doing uh definitely we will go ahead we will learn russion once again at the time I will explain but just for time being you can just uh relate if you already know so you might have heard that whenever you are trying to call a factor faal of four a function activation record a stack frame is created for the factorial of four which is internally calling kind of factorial of three which is inter calling factorial of two which is calling a factorial of one which is calling say factorial of zero what is happening the number for which you are trying to call the factorial those many function calls are made and if those many function calls are made if those many function calls are made with those function calls will take some space occupied onto the stack oh yes it will take some space occupied onto the stack I'm talking about that so you go back so in this case the space complexity the space required is probably proportional to n as the more bigger number you're trying to calculate the more function function activation records need to be cre on stack I can say that in this case that not really time I should say that space is proportional to n and the space is proportional to n we can say that it is of order of n or for that sake most common example a graph you try to create a graph of let's say V vertices to create a graph of V vertices we say that we need to create a matrix we need to create a matrix of V by V Matrix you are creating a matrix of V by V Matrix so you can say that the space is proportional to n where let's say n sorry space is proportional to n Square where n is number of vertices in that BL case Matrix a 2d array 2D array is n by n array so obviously the space required is of order of n s so this is like pretty simple what I'm trying to say that like like a order of so here you are not talking in terms of how many bytes are we talking in terms of bytes no not at all we are not talking in terms of bytes but we are talking in proportion to some Factor either the number whose factori you want to calculate or the number of vases or number of Ages or let's say height of a tree or for that sake whatever it could be correct or number of elements in Array so with respect to something you are trying to tell the proportion how much space it is going to occupy so that is called a space complexity but then you continue further a Time complexity the time complexity where we say that the unit time required to complete any algorithm we are not talking about how many millisecond or how many microc or how many nanocs are required because those will change heavily depending on your computer depending on configuration of your computer depending on architecture of your computer so I do not want to talk about that so what exactly it is it usually you say that it is approximate measure of time required to complete any algorithm complete any algorithm wait for a minute uh what that based on some factor with respect to some Factor so whatever time that we are talking about we are always saying that it a time with respect to something the time with respect to something so with respect to this with respect to that whatever you said but it is with respect to something uh as I told you it could be like how many elements in Array it could be how many elements are there in link list it could be what is the height of a tree it could be how many vertices and edges that you have got whatever so it depends on the data structure it depends on the you know what values that you are trying to find out but you need to find out the proportion cheese Factor grow to corresponding know that study is referred as a Time complexity if you are like absolute beginner usual mistake that we always do is that we always consider that this many millisecond is better than this many milliseconds but that is just a time here we are not at all finding how much time is there rather we are trying to find out it time required will depend on which factor and then in which proportion the time will change like I'll give you example again 100% or like return rule but but we can always say that the time required is proportional to the number of iterations that are Carri out and that is why you say that the time complexity of any algorithm depends on time complexity of any algorithm depends on the number of iterations in that algorithm so number of iterations are more you say that the time required is more number of iterations are less you say that time required is less it's that simple so you just continue further like again the common time complexities and its General significance I'm trying to tell you or kind of rough idea I want to just give you over here the time complexity the most common time complexity is trust me so ultimately as you progress with the module comp so almost all I have just taken up except few of graph because they are kind of combinations the very first a o of one what is O of one o of one I say that the time is a constant time the time required is a constant time it is not dependent on any Factor any Factor so whether you are searching in 10 elements whether you are searching in 10,000 elements when you say that the time is going to remain same the time complexity is said to be o of one okay that is good o of n o of n the time required is proportional to n now when say time required is proportional to n again you take a example of a factorial program itself factorial in a factorial program what happens you write a loop for I is equal to 1 I is less than or equal to n i ++ result is equal to result into I but your Loop is going to run how many times depends on a value of n so if your value of n is 10 the loop is repeated 10 times if value of n is let's say thousand then it is going to repeat for thousand times and if the value of loop is let's say 1 million it will repeat 1 million times what exactly I want to say I want to say that the bigger is the number more is the time it will take more is the time that it will take so here it depends on the number whose factorial you want to calculate and whenever you see that it is of usually again but I'm just trying to tell you the general observations these are the general observations usually that program involves a single Loop so most of the cases you will find that program single Loop then it will be like o of n okay that is good I'll just continue further then going ahead it is o n Square what is o n Square you saying that the time required is proportional to n Square so any example a typical algorithm selection sort bubble sort what is that these sorting algorithms they all will be coming like a o Square o n square is a typical example I would say that it is a nested Loops nested Loops nested Loops in the sense I'm Loops inside loops and how many nested Loops I that two nested Loops two nested Loops one within another you can say that it is o n Square jav selection meaning I'm saying that Loop iterations inner loop is repeated each time for the outer loop so outer loop Lo n s okay that is good then what is o n Cube o n Cube that you can see it is where again it is a nested Loops but it is now Loop within Loop within Loop so there are three Loops back to back a three Loops back to back you can say that it is o n Cube so do you know any algorithm yes I know the algorithm that is the only reason I have written there waral Floyd algorithm yeah B time probably on the last day we will talk about that but veral Floy algorithm is typically a graph algorithm and the graph algorithm yes it will take it will take three Loops I source and destination or loops loops the complexity nbe now you go ahead let's say o of login what is O of login you are saying that the time required is proportional to log but again you as a question how you can say that it is proportional to log I'll give you some example a typical example where the partitioning is involved your whole array you're are trying to not necessar you talk about any example divion partitioning is involved I'll give you some simple program write a program to convert like a decimal to Binary decimal to Binary conversion using using not using bitwise operators using kind of a division method what we call a double dable method I hope you must have heard of it you take a number you divide you take a you record the remainder again whatever is the result again you divide by two again you record the remainder and again you divide by two again you record the remainder and you're going like a reverse way whatever number that we have got we are dividing by two dividing by two divide by two divide by two and we are trying to reach to the zero are chances are that the log factor is involved the log factor is involved yes binary search is the best example where you can find that the log and you can see don't worry so you'll be able to compare and you will be able to appreciate that as well going ahead o n log n what is n log N I said that the time required is now proportional to login now what is this in this case again login factor is talking about partitioning but the partitioning is also repeated it is not one time partitioning if it is like one time partitioning that is fine then you say login but if this partitioning is done each time then you go for n login and again best example would be quick sort M sort or kind of Heap Sort where the time complexity comes out to be o of and login I'll take up one two problems as I said that the algorithm requirement requirement we should be able to think a little we should be able to think a little so I will just ask you for some problems I'm not expecting that you people write a code I'm very sure you must have written a code sometimes uh somewhere and then recalling that if you could tell me what could be the time complexity that will be great like one let's say for example I'm just going ahead I'm just going ahead the first one uh check if number is prime check if number is prime I'm not looking for the efficient implementation I'm looking for a normal implementation no efficient implementation I'm not looking for any kind of efficient implementation yes the time comp lexity will be o of n if why time complexity is O of n because reason is very simple typically the loop that we write is something like this for I is equal to 2 I is less than n i ++ and inside that we check if n mod by 2 is equal to equal to zero then we simply say that this is not prime this is not prime otherwise otherwise we can say that it is prime something like this yes such kind of simple implementation we might consider isn't it yes absolutely so I'm saying that in this BL case what is important what is important you take a look at oh sorry my mistake not mod even number check yes I got it it should be n mod by I so number number if it is divisible till number minus one two to that number minus one anywhere you find it divisible you say that it is not prime number but if it is not divisible by any of that then you say it is a it is a prime number absolutely there what is important over here is a loop and this Loop Number of iterations are dependent on a number of iterations dependent on value of n so you as your n grows the number of iteration grows in the same proportion so I can say that the time complexity over here should be considered as o of n I'll take up like one more example one more example let's say find all combinations of a a b and c so given three characters I want to find out all possible combinations let's say a BC AC b or whatever so what you need I guess typically you need to run three Loops isn't it yes you need to write three loops and as you are writing three Loops you always say that it could be then in this case o n Cube so I'm saying that it is three nested Loops that you can use and the three nested Loops it will say that time complexity should be o n but I repeat number of iterations are they really changing with respect to something or they are going to remain same so before you answer before you come up with the conclusion so o n Cube you are saying that because it is like taking three nested Loops yes A B C but as I said that let's say for example a c d then probably will be four Loops Loop but as long as you changing XY now you'll find that it is not really changing with respect to it is not changing with respect to uh how which characters that you're using it is changing how many characters are there you please keep this in mind so before you answer you need to always say okay what exactly is it really changing CR I'll take one more example and then we will move on to the actual work and I want you people to think a little I want you you people to think around this and then answer me because it is this is bit tricky this bit tricky so print print table of n a table m 2 1 are 2 2 2 are 4 2 3 are 6 2 10 are 20 this is what you call it as a table so given number table print so what do you believe what is the time complexity yes that is good like people are thinking and many of them are thinking so that is really good sign I said that time complexity will be of one now you ask the question of one loop loop is it dependent on any Factor you always know that you always know that your Loop will be something like this for I is equal to 1 I is less than or equal to 10 I ++ I ++ and simply you want to print number into I this is what all you doing so n one n 100 n 1,000 is it going to make a change into the number of iterations not really and if it is not going to make a change in number of iteration you should not blindly just say that the time complexity is let's say of blindly care then it is very dangerous I hope you got the point and this is something that I'm trying to tell you always time complexity rough ideas examp what is more important is that you should always once you can just guess something no doubt on that but after you guess you should at least think logically is okay you need to rethink on it right so going ahead to sir you say that it is order of or you call it as let's say Big O not sorry order of or you call it let's say Big O notation so do you believe that that is the only notation available or not really huh so is it only available or not really so you find that Big O is kind of one notation but apart from that there is another notation called Omega notation and there also notation called a Theta notation so what these notations are all about and why the multiple notations are there to be frank there's a lot of you know mathematical jargon behind it but to keep it simple to keep it simple the Big O notation talks about the upper bound upper bound or you can say that how much time maximum it will take to run this algorithm one talks about lower bound how much is like a minimum time that it will take to run the algorithm and where Theta where you try to be bit more precise what is the maximum and what is the minimum time correct so upper bound you talk about the maximum time complexity then I can say that like a maximum time maximum running time uh this one [Applause] [Music]