hi the topic is Huffman coding Huffman coding is a compression technique it is used for reducing the size of data or message suppose you want to store the data in a file so you can store the data in compressed form to reduce the size of a file when the data is sent over a network data can be compressed and sent to reduce the cost of transmission in this video I'm going to explain you if a normal message is sent what will be the cost and what is the fix size and coding then what is variable size and coding that is Huffman coding now let us study the problem I have a message here now this message I want to store it in a file or I want to send it over a network then let us understand what will be the C cost of a message so the cost of this message or the size of the message will be measured in terms of bits let us check first of all there are 20 letters in this one so the length of this message is 20 next how this message has to be sent it has to be sent by using asky Code electronic devices or computers all use aski codes for characters or English alphabets so these are all characters asky codes are 8 Bits I have used alphabets a to e here so that is easy to understand for us so if I say a it's ASI code is 65 and the binary form is this one so total eight bits these are eight bits that are representing decimal 65 and that is representing a similarly if I say B then it is 6 6 this will be for 66 likewise c d e for everyone we have that this is 667 and 68 and 69 and here the binary code will be there so eight bits are there for each alphabet now if normally this message is sent 8 bit for each alphabet then total number of bits will be how much as there are 20 alphabets in this message so this will be 8 into 20 that is 160 bits size of the message will be 160 bits now this is the simple message send without encoding the size will be 160 bits 8 bit for each alphabet now let us look at can we use our own codes instead of aski codes how it is possible see I'm not using all English alphabets or all possible symbols on the keyboard I'm not using every symbol from the character set I'm using only five alphabets that two capital letters then do I need eight codes eight bit codes for representing just five alphabets no few bits are sufficient so can I use my own codes with less amount of bits yes so next we will see fix size codes here I have taken alphabets in this message and how many times each alphabet is appearing I have written the count here or you can also call it as frequency a is appearing three times 1 2 three likewise we can check all how many times they are appearing I have written them here total there are 20 alphabets if you want to see the frequency then you can say this is 3x 20 that is 3x 20 or this is 5x 20 because total number are 20 so this is 6X 20 and you can take the ratios I prefer taking counts that is easy for working even what should be the code see I have five characters I don't need eight bits for just five characters 8bit aski codes are for 128 characters or 128 symbols but for only five let us see if I have just one bit one bit bit then either I can write zero or one so how many symbols I can represent how many characters only two characters if I have two bits then how many I can represent I can write 0 0 0 1 1 0 1 1 so I can have four different combination and each combination can represent one symbol but I have five so for that I can take three bits so in this how many combinations are possible 0 to 7 that is eight combinations are possible so I will take five out of that so let us say in three bits I will say a is 0 0 B is 0 0 1 C is 0 1 0 D is 0 1 1 and E is 1 0 I have given my own three buil codes I will use this for encoding this message and I will this will reduce the size of the message so in me it means here instead of writing aski code I will be writing 01 for B and 0104 C likewise go on when the message is encoded using this one then what will be the size of the message as we know well that there are 20 characters and each takes three bits so this will be 60 bits so size of the message will be 60 bits and one more important thing we cannot neglect what is that when I am sending a message suppose encoded in this one now how the receiver will know what are the codes even if I store it in a file and then later I want to retrieve how do I remember what are the codes use 0 0 means a only is it see for making it easy I have taken the alphabets a to e here the alphabets can be anything this can be a this can be M this can be o this can be Q then how I can know which code is for what so I should also have the codes that is this table also along with the message so this is encoded message and this is the table use this table to decode the message yes so message is 60 bit then you need the table also the chart of codes that will help to decode this message so let us see you have to send this one also how much size this will take see I have five alphabets this alphabet should be in original form now now standard is what asky code so I must write asky code of all these asky code of all these so for this eight bits so total how many five so 5 into 8 Bits this is for what characters or symbols then for each three bit code for a this is the code B this is the code for everything I should also have the code so total how many five and how many bits for each code three so this is for codes so this makes how much This is 40 + 15 this is 55 and what is the size of this original message so message is 60 bits right and table or a chart of codes is 50 55 bits so total how much this will be 115 bits yes so total size of the message along with the chart is 115 bit it's not just 60 bits it is 115 bit no doubt the size of the message is reduced but table is also important so it was 160 now it became 115 so around 35 to 40% of reduction in size from 16 to 115 right so this is one method with fixed size codes now we'll go to variable size code and let us follow Huffman coding which will still reduce the size of the message Huffman and coding Huffman says that we don't have to say take fix size codes for the alphabets some characters or alphabets may be appearing few times less number of times and few may be appearing more number of times so if you give small size code for the more appearing characters then the size of the entire message will be definitely reduced so let us see what is his idea already we have this table all the alphabets and how many times they are appearing in a message so that gives the frequency of those alphabets now Huffman code follows optimal merge pattern now we have to generate our own code so what should the method for the code so Huffman has given an approach for getting our own variable size codes so he says that all those alphabets should be arranged in the increasing order of their count so this is the least one and this is the next one and next one and so on so they are arranged in the increasing order of their count or frequencies so the first the smallest one then the highest one so this optimal merge pattern should be followed on this one so what I should do merge two smallest one and make one node so this is 2 + 3 this is 5 now next select two smallest and form a node so 5 4 5 6 these are remaining out of this which are two smaller either I can take this 54 or that 54 so I will take this one so I'll combine this one with this so this is nine now what are the list I have or the notes I have 9 5 6 these are the two minimum so so combine these two this is L then combine these two two are remaining now so this one and this one so this gives what 20 so here we got a optimal merge pattern tree so actually we followed optimal merge pattern that is 3D approach always select two minimum one and we got this one now this tree will help help us Define the codes how on the left hand side edges mark them as zeros and on the right hand side edges mark them as one that's it now what are the codes for each alphabet follow a path from root onwards so for a what is the code 0 01 so a is 0 01 then B is 1 0 1 0 c 1 1 1 1 D 01 01 and E 0 0 0 0 0 0 that's it these are the new codes we have now you can see the some code is of three bits and one code is of two bits like that so even we may have the codes with one bit also not here in some examples so variable size codes are there now I can use these codes for encoding my message like B is 1 C is how much 1 1 C is 1 1 and a is 0 0 1 B is 1 0 B is 1 0 and D is 0 1 0 1 go on if I use these codes what will be the size of my message so for that how many bits are there for a three bits and how many times a is appearing this is 3 into 3 9 and two bits and this appearing for five times so 5 into 2 10 two bits two bits one one appearing for six times so 6 into 2 12 two bits appearing for four times so 4 into 2 8 and three bits appearing for two times so 2 into 3 is six so for entire message I have how many times each character is appearing and their sizes of codes I have taken and I got this one now total number of bits are 45 bits size of the message is 45 bits means if I encod all I just I just need 45 bits so the message size is 45 bits now one more thing we should consider along with the message I should also send this chart or a table or a tree then only decoding can be done mean along with the encoded message what is the codes what are the codes used that should also be there then only decoding can be done so somehow this treay should be preserved or the table should be preserved or you to see what will be the size of the table on all these alphabets I should send their asky codes the standard code so 8 bit of asky code how many alphabets are there five so this makes how many 40 bits then codes also I should send so this codes when they are stored so how many codes are there five codes but what are the number of bits 1 2 3 4 5 6 7 8 9 10 11 12 so this is forming 12 bits so together this 40 + that 12 so 52 bits are required for tree or a table tree or table so what is the total size message is 45 bits and the table or tree is 52 bits and this will be 97 bits yes now you can see that it is still reduced from fixed size codes so that's all about Huffman coding now if you want to know the size of the message that 45 you can know it from the tree also how see this is the distance how much is the distance 1 2 3 and frequency is what 2 so 3 into 2 so distance into frequency of each or count of each you can take Sigma sum of all these so what this will be distance is three and frequency is 2 plus distance is three and frequency is three plus distance is two and the frequency is four distance is two frequency five and distance is 2 and frequency is 6 so this is nothing but this calculation that we got and this will be 45 bits only so if you want to know what will be the size of the entire message from the tree also you can find out by using this formula if you refer a video on optimal merge pattern you find that formula is defined let us see how decoding is done this is the message now in the completely in the binary bits form follow the message for this you must have a tree for decoding so start from root 0 left side 0 left side one right side this this is b b 0 0 0 1 completed then again start from the root one right side again one right side so we reach the leaf that is C so these two are over then again once you have reached the leaf again start from the root one right side one right side so this is C the next zero left side one right side it is a d so these two are com in this way this message can be decoded and from binary bits we can get back the original asky code so the receiver can convert the message into asky code and use it in its machine so inside the machine it while using it will not be using the code so it has to convert into ask key codes like when you have any zip file or compressed file you have to decompress for using it same way it should be decoded and used so that's all about Huffman coding