hey everybody welcome to your video on algorithm time complexity and Big O notation we're going to go through some really common examples of algorithms and understand time complexity so as soon as people start talking about this on YouTube or in class they always start pulling out a bunch of numbers and I'm not saying that's not valuable but for a software developer I think it's more important just to understand some common examples and understand it more practically so that's my goal here mainly because I stink at math and I don't want to go into all that so we're going to just go through some concrete examples so where do we even start let's first try to understand the purpose of time complexity and how to think about it so when we have some algorithm basically some code that processes data it might take a certain length of time and we want to know which algorithms are faster so how do we measure this well you know you might think hey why don't we just time it and say this one took 10 seconds we Tred some other algorithm it took 20 seconds GH that one's slow well seconds are not really a good way to measure this because for one you could put it on a different computer and it might be faster or slower plus it doesn't really talk about how the algorithm scales it's more about as we increase the size of data that we're processing how the algorithm speed changes so that's the purpose of Big O notation is to not worry about a specific time to process a a certain amount of data but more a way to classify how fast it is another way you could think about this is let's say you were walking and your friend was driving so this is you I cannot drive cars looks like a hat or a mustache or something anyways this is someone driving all right and I told you guys the first person to get 10 ft wins so so like very close now if you were just ready to go you could probably Sprint past that point before this person had the time to turn on their car put it in drive and get across that point so when you're working with this very small distance you can see this one's actually faster in terms of time but what if I told you now you have to go 10 miles and the first person to get there wins obviously the car is going to win because that startup time is so insignificant but it's so much faster to get that 10 miles than if you were walking this might be a weird example but the same concept applies to algorithms we start off by working with a very small set of data certain algorithms might be faster than others but as you increase the size of data and you're no longer working with just a very small set of data you're working with a huge set of data you can really see what algorithms are faster so cars are obviously faster than walking bicycles are somewhere in between they're different classifications so we're going to take these concepts of the different classifications and apply them to algorithms when we're dealing with the different algorithms there's often going to be an input of the size of data we are working with so imagine an array of numbers this could be your input and the size here is four but we also might want to process a different array that has 4 million pieces of data so instead of just having a specific number like four we generalize it and say n so n represents the length of the data so a classification of algorithms you might run into might look like this o and then in parentheses you see n so the O this represents Big O and you can look up the mathematical meaning of that there's also like big Theta and junk like that but the main thing you need to understand is that when we see o with something in parenthesis here we are measuring the complexity of an algorithm so if we have Big O of n it's saying that the operation is dependent purely on the length of the data and and I'm going to show you an example of an algorithm that is O of N and then we can look at some variations to understand some other algorithms all right so we have this collection of a bunch of numbers and I want you to find the number three obviously using your eyeballs you can see it's right there so it's really simple but imagine this is a very large list you're not going to be able to use your eyeballs like that so you're going to tell a computer to do it how is the computer going to do it well it's actually just going to search through this element by element until it finds what you're looking for so there is 1 2 3 4 5 6 7 8 nine elements so n is nine and the computer is going to look at the first number and say is this three no it's not is this three no it's not is this three no it's not is this three no it's not you guys get the point and and in the absolute worst case scenario three is at the very end and it takes nine operations to find it it basically checked every single one until we get to the ninth one and it finally finds it so that is why this this searching algorithm is said to be o of n another way to think about it is if you doubled this list well now it's going to take twice as long because it has to search through twice as many numbers so it's always dependent on the size another example instead of a search you might be looking for the maximum number so You' basically keep track of the highest number so you'd start at the beginning so you would just say Max is data index zero so to start off Max is 10 and then each time it Compares is 24 larger yes it is so that new Max is going to be 24 is five larger no is seven larger no is 13 larger no 120 yep that is so it's going to replace it it's 35 No 72 no three no so it basically has to go through every single element do a comparison and if it's larger than the max replace the max so that is how you would find the maximum inside of some set of data and this algorithm is O of n so if it helps you can just think of O of n as the standard it just iterates through the entire collection and finds whatever you're looking for but there are other classifications of algorithms that are much faster and other ones that are much slower so let's talk about some of the other classifications so let's do a chart here and let's say this down here is the size or in other words N how big the input is and let's say this over here is the number of operations so how would we graph o of n well as the size of the list increases it increases in operations equally so we get a perfect line so if n was 10 the number of operations would be 10 some algorithms are actually much slower and they are classified as n s algorithms so it's going to look something like this and it's going to be o of n^2 so if there's 10 elements then there's going to be 100 operations so that is one of the worst what's a really good one well there's another classification which is actually just constant time and you can basically think about that as being instantaneous so this is O of one that's how you write it constant time an example of this is if you want to grab a particular element in an array where that array is all one set of memory where everything is connected and each individual element is the same size you can just take that size multiply whatever index you're trying to get and you'll get that data we're going to get into some more constant time examples here in a minute but for now let's talk about some of the other classifications there is n factorial which if you can imagine n^ s being slow then n factorial is like so slow so this this is going to be Big O of n factorial there's another one in here which I'm kind of running out of room here but that is going to be Big O of 2 to the N we're going to have the square root of N and then another one which is log of n so these are the different classifications going back to that silly example I gave you earlier this is walking to a different state this is driving to a different state State actually maybe this is driving to a different state this is flying to a different state this here is teleporting to a different state although if you're walking with someone and someone might be a little bit faster it doesn't even matter because you're still so dang slow compared to these ones over here now I want to take a look at some constant times so to understand this I want you to understand a data structure known as a hash table and here's how a hash table works it allows us to store data similar to how an array would work however the way the order in which it's stored is different so we basically have this thing called a hash function and when we want to store data in this data structure which I'll draw it over here we don't just store the data itself we also store a key so I have a key and a value so let's say we wanted to associate a user ID with a person's name we might take ID of five Caleb and when we do this that key is processed through this hash function and that is used to determine a particular spot to store this element inside of the hash table so here's where Caleb's going to go internally this might be stored at index 3 it could be stored at index 200 it doesn't matter all we need to know is that it process through this hash function to get us that number and we'll probably do a video dedicated to Hash functions and hash tables so I don't feel like you have to understand how this works I just want you to understand what it does and we'll get into how later so what it does is it takes that key converts it to some index and stores it in this structure well let's say we did that with a bunch of data so we passed more data into this hash function and it looks something like this a bunch of key value pairs in this structure and let's say we want to grab the person with the ID of three so what we would do is we would index and use three the key to grab that data it's going to take that key process it through the hash function and immediately know where to find that data this is an example of a constant time process it's constant time because it goes directly to that position if instead we had an array of these numbers and I wanted to find three in here I would have to search through each element to figure out if it's it for here since we're using that key it just jumps to that position and automatically gets us that value Sally so hash tables are extremely efficient for inserting data as well as retrieving data so that that is a very common use for them is if you need to insert a lot of data quickly or retrieve data very quickly based on the key though you're finding it based on the key if you wanted to search and find Sally that's not going to be quite as easy because it doesn't have any knowledge of where Sally is because Sally was not used for the hash function the key was used for the hash function that's how it determines where to store it when you're looking for Sally you use Sally's key to find all of her information now I want to go through another example of a constant time using an array all right so here we have an array and now we're going to access the data using positional indexes and you might be wondering what is this 0 4 8 12 16 well consider these to be Memory addresses so at the very beginning we start at zero and an integer 32 bits so after four bytes we got that next integer and then another four bytes we have that next integer another four bytes and so forth so let's put some data in here we can store whatever we want in here assuming they're integers doesn't matter what the numbers actually are themselves but they have to be integers this explains why arrays are typed when you're working in a programming language let's say Java as an example you might do something like this where you type to an integer array and then you give it a name such as grades so internally the storage might look something like this now let's say we want to grab an element so we pass in an index and we'll just say this is an array called grade so to call it it might look like this and let's say we grab index 3 well it knows that the start is right here this is the start this is index zero this is index one this is index 2 this is index 3 and this is index four so we're trying to grab this element right here so a constant time process that we could create to jump to this position would look like this four which is the size of an integer and you're never going to have to do this in a programming language like Java but this might happen internally um so you could say size of int multiply that by three the index what does that give us 12 so it immediately jumps to memory location 12