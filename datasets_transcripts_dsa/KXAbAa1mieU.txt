hello friends and welcome to this video in which we will learn about some of the techniques using which we can easily calculate time complexity of algorithms without complex calculations so let's get started one thing to be noted is that time complexity is analyzed for very large input size and worst-case scenarios now let's take an example and try to come calculate its time complexity so we have TN which is equal to 2 n square plus 3 n plus 1 the first step is to drop the lower order terms that are 3 and plus 1 in this case next we drop the constant that is 2 so we get the time complexity as Big O of n square for this particular polynomial now let's look at some rules for finding out the time complexity in algorithms first let us look at how do we calculate the time complexity of a single loop so this is our for loop which runs from 1 to N and we have this expression inside the for loop X equal to y plus Z which takes constant time to execute now the time complexity will be n times time taken for this expression which is a constant let's say C so the time complexity will come out to be C times n and in Big O terms we can neglect this constant and simply write the time complexity as Big O of n now let's look at nested oops as you can see we have two loops which are nested let's try to find out the time complexity so this is the expression which takes constant time to execute now we simply multiply the time complexity of each loop so this is the outer loop which will run n times and for each run of the outer loop this inner loop will also run n times so the total running time will be some constant time multiplied by n into n which is equal to n square so we can say that the time complexity is Big O of n square next are the sequential statements let's say that we have an expression which takes constant time to run let me denote it by c1 after that we have this for loop which we have seen before and it will take c2 times n time to run then we have another for loop which takes c3 into and time to run so when we have sequential statements like these we simply add the time taken for each statement so let me do that in Big O terms we can ignore these constants c1 c2 and c3 and we have the time complexity as Big O of n next let us look at how do we find out time complexity when we have conditional statements such as if-else we evaluate the situation when values in if-else conditions cause maximum number of statements to be executed so let's say that inside this if condition we have a for loop whose time complexity is Big O of n and inside this else condition we have a nested for loop whose time complexity is Big O of n square so we consider the else condition as it has a greater time complexity and hence the overall time complexity will come out to be Big O of n square now let's look at the comparison of time complexities so we have Big O of 1 which is the smallest and the best then we have Big O of log n then comes Big O of n then it is Big O of n log n then we have exponential time complexities and finally we have Big O of n factorial which is the worst this is a chart of time complexity of various sorting algorithms it is highly recommended to learn them by heart as it comes very handy alright so till now we have only talked about time complexity of a program however there is another factor which affect the execution of a program which is space space complexity of an algorithm quantifies the amount of space or memory taken by an algorithm to run as a function of the length of input let's quickly understand it with an example assuming that an integer takes 4 bytes of storage in memory and in this piece of code we have four integers a b c and z so the total space will come out to be 4 into 4 plus 4 this additional 4 is for the return statement hence this comes out to be 20 bytes so this is a constant space running algorithm there is usually a trade-off between optimal memory use and runtime performance in general for an algorithm space efficiency and time efficiency reach at opposite ends and each point in between them has a certain time and space efficiency so the more time efficiency you have the less space efficiency you have and vice versa for example merge sort is exceedingly fast but requires a lot of space to do the operations on the other hand the bubble sort algorithm is exceedingly slow but it requires the minimum space so by now you should be easily able to calculate the time or space complexity of a program that's all for this video thank you for watching